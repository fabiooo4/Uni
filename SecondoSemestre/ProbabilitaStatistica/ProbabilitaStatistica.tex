\documentclass[a4paper]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[italian]{babel}
\usepackage{amsmath, amssymb}
\usepackage[makeroom]{cancel}
\usepackage{amsfonts}
\usepackage{mdframed}
\usepackage{xcolor}
\usepackage{float}
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{pgfplots.fillbetween, pgfplots.statistics}
\pgfplotsset{compat=newest, ticks=none}
\usepackage{graphicx}
\graphicspath{{./figures/}}

\pgfdeclarelayer{ft}
\pgfdeclarelayer{bg}
\pgfsetlayers{bg,main,ft}

\usepackage{import}
\usepackage{pdfpages}
\usepackage{transparent}
\usepackage{xcolor}

\usepackage{hyperref}
\hypersetup{
    colorlinks=false,
}

\usepackage{ntheorem}
\newtheorem{theorem}{Teorema}

% Useful definitions frame
\theoremstyle{break}
\theoremheaderfont{\bfseries}
\newmdtheoremenv[%
	linecolor=gray,leftmargin=0,%
	rightmargin=0,
	innertopmargin=8pt,%
	ntheorem]{define}{Definizioni utili}[section]

% Example frame
\theoremstyle{break}
\theoremheaderfont{\bfseries}
\newmdtheoremenv[%
	linecolor=gray,leftmargin=0,%
	rightmargin=0,
	innertopmargin=8pt,%
	ntheorem]{example}{Esempio}[section]

% Important definition frame
\theoremstyle{break}
\theoremheaderfont{\bfseries}
\newmdtheoremenv[%
	linecolor=gray,leftmargin=0,%
	rightmargin=0,
	backgroundcolor=gray!40,%
	innertopmargin=8pt,%
	ntheorem]{definition}{Definizione}[section]

% Exercise frame
\theoremstyle{break}
\theoremheaderfont{\bfseries}
\newmdtheoremenv[%
	linecolor=gray,leftmargin=0,%
	rightmargin=0,
	innertopmargin=8pt,%
	ntheorem]{exercise}{Esercizio}[section]


% figure support
\usepackage{import}
\usepackage{xifthen}
\pdfminorversion=7
\usepackage{pdfpages}
\usepackage{transparent}
\newcommand{\incfig}[1]{%
	\def\svgwidth{\columnwidth}
	\import{./figures/}{#1.pdf_tex}
}

\pdfsuppresswarningpagegroup=1

\begin{document}
\input{title.tex}

\tableofcontents
\pagebreak

% Libro: S.M ROSS, Probabilità e Statistica per l'ingegneria e le scienze Apogeo, 2015 (ed. 3)

\section{Cos'è la probabilità e la statistica?}
La statistica è una scienza che si occupa di raccogliere, organizzare, analizzare
e interpretare i dati. Nella statistica si cerca di estrapolare informazioni da
esperimenti \textbf{aleatori} (esperimenti che non si possono ripetere esattamente allo stesso
modo) e di prendere decisioni basate su queste informazioni. Ogni esperimento aleatorio
ha bisogno di un \textbf{modello probabilistico} che ne descriva le caratteristiche principali.

\subsection{Popolazione, variabili e campione}
\begin{itemize}
	\item \textbf{Popolazione}: tutti i possibili oggetti di un'indagine statistica
	\item \textbf{Individuo}: un singolo oggetto della popolazione
	\item \textbf{Variabile}: una qualsiasi caratteristica di un individuo della
	      popolazione soggetta a possibili variazioni da individuo a individuo; è l'oggetto
        di interesse in uno studio
	\item \textbf{Range della variabile}: \( R_x \) è l'insieme di tutti i possibili
	      valori che la variabile \( x \) può assumere
	\item \textbf{Campione}: un sottoinsieme rappresentativo della popolazione
	      composto dalle variabili relative ad un sottoinsieme di individui
	\item \textbf{Realizzazione del campione di dimension \( n \)}: (post esperimento)
    le osservazioni del campione:\[
      \underline{x} = (\tilde{x}_1, \ldots, \tilde{x}_n)
    \] 
  \item \textbf{Range dei dati}: \( \mathcal{R}_{\underline{x}} \) i valori che la
    variabile può assumere tra il minimo e il massimo
\end{itemize}

\subsection{Parametro e Stima}
\begin{itemize}
	\item \textbf{Parametro}:una misura che descrive una proprietà dell'intera popolazione
	\item \textbf{Stima}: una misura che descrive una proprietà del campione e che
	      fornisce informazioni sul parametro
\end{itemize}

\subsection{Variabili}
Le variabili possono essere di diverso tipo:
\begin{itemize}
	\item \textbf{Variabili qualitative nominali}:
	      \begin{itemize}
		      \item \textbf{Ordinali}: possono essere ordinate
		      \item \textbf{Non ordinali}: non possono essere ordinate
	      \end{itemize}
      I valori che assumono si definiscono anche \textbf{modalità}
	\item \textbf{Variabili quantitative}:
    Sono valori numerici e si distinguono in:
	      \begin{itemize}
		      \item \textbf{Aleatorie continue}: derivano da processi di misura e assumono
		            i loro range (valori che possono assumere). Sono sottoinsiemi reali
		      \item \textbf{Aleatorie discrete}: derivano da processi di conteggio e
            assumono valori interi
	      \end{itemize}
\end{itemize}


\section{Statistica descrittiva}
Consiste nella raccolta, organizzazione, rappresentazione e analisi dei \textbf{dati}.

\subsection{Strumenti di sintesi}
\subsubsection{Tabelle di frequenza}
Sono tabelle di frequenze di individui con una certa caratteristica o aventi una caratteristica
appartenente ad un certo intervallo.
\begin{itemize}
	\item \textbf{Frequenza assoluta}: conteggio del numero di individui
	\item \textbf{Frequenza relativa}: percentuale del numero di individui
	\item \textbf{Frequenza cumulativa}: conteggio o percentuale del numero di individui
	      fino ad un certo punto
\end{itemize}

\subsubsection{Distribuzioni}
Sono rappresentazioni del modo in cui diverse \textbf{modalità} si distribuiscono tra
gli individui di una popolazione.
\begin{itemize}
	\item \textbf{Caso discreto}: \( f \): valore variabile \( \to  \) frequenza relativa
	\item \textbf{Caso continuo o numerabile}: \( f \): intervallo di valori variabile \( \to  \) frequenza relativa
\end{itemize}

\subsubsection{Distribuzioni cumulative}
Sono distribuzioni che rappresentano la frequenza cumulativa di una variabile. Possono essere:
\begin{itemize}
	\item \textbf{Caso discreto}: \( f \): valore variabile \( \to  \) frequenza cumulaiva
    relativa
	\item \textbf{Caso continuo o numerabile}: \( f \): intervallo \( \to  \) frequenza 
    cumulativa relativa
\end{itemize}

\subsubsection{Grafici}
Sono rappresentazioni grafiche delle distribuzioni. Possono essere:
\begin{itemize}
	\item \textbf{Istogrammi}: è costituito da rettangoli, insistenti sulle classi
	      della partizione, attigui le cui aree sono confrontabili con le probabilità.
        \[
        \text{area rettangolo} \quad i = h_i \cdot |\pi _i| \approx P_X(\pi ) \approx f_i
        \] 
        \[
          h_i = \frac{f_i}{|\pi _i|} \quad \text{per ogni} \; i \in I
        \] 
      L'area del rettangolo che insiste sulla classe \( \pi_i  \) della partizione è pari
      alla frequenza relativa della classe, quindi l'area torale è 1.
  \item \textbf{Diagrammi a barre}: rappresentano le frequenze di una variabile. Le barre
        sono separate e la loro altezza è proporzionale alla frequenza
	\item \textbf{Diagrammi a torta}: rappresentano le frequenze relative di una variabile
	\item \textbf{Boxplot}: rappresentano le frequenze di una variabile
  \item \textbf{Poligono di frequenza (ogiva)}: è un grafico a linee continue che ha
    sull'asse delle ordinate le frequenze cumulative. Questo tipo di grafici è il più comune
    per rappresentare le frequenze cumulative.
\end{itemize}


\section{Frequenze}
Siano \( \underline{x} = (\tilde{x}_1, \ldots, \tilde{x}_n) \) una realizzazione del
campione di dimensione \( n \) e \( \mathcal{R}_{\underline{x}} \) il range dei dati.
Si dice \textbf{partizione} di \( \mathcal{R}_{\underline{x}} \):
\[
  \pi = \{\pi_i\}_{i \in I}
\] 
La \textbf{classe i-esima} è l'elemento i-esimo della partizione

\subsection{Frequenze campionarie}
\subsubsection{Frequenza assoluta}
Si dice \textbf{frequenza assoluta} \( n_i \) per ogni \( i \in I \) il numero di
osservazioni che appartengono a \( \pi_i  \), cioè:
\[
  n_i = card(\tilde{x}_j \in \pi_i, \quad j = 1, \ldots, n) \quad \text{(cardinalità)}
\] 
\[
  0 \le n_i \le n, \; \text{per ogni}\; i \in I \quad e \quad \sum_{i \in I} n_i = n
\] 

\subsubsection{Frequenza relativa}
Si dice \textbf{frequenza relativa} \( f_i \) per ogni \( i \in I \) la percentuale delle
osservazioni che appartengono a \( \pi _i \), cioè:
\[
  f_i = \frac{n_i}{n}
\]
\[
  0 \le f_i \le 1, \; \text{per ogni}\; i \in I \quad e \quad \sum_{i \in I} f_i = 1
\] 

\subsection{Frequenze cumulative}
\subsubsection{Frequenza cumulativa assoluta}
Si dice \textbf{frequenza cumulativa assoluta} \( N_i \) il numero di osservazioni che
appartengono alle classi \( \pi_h \), con \( h \le i \), cioè:
\[
  N_i = \sum_{h=1}^{i} n_h
\] 
\[
  0 \le N_i \le n, \; \text{per ogni}\; i \in I \quad e \quad N_i \le N_j, \; i<j
\] 

\subsubsection{Frequenza cumulativa relativa}
Si dice \textbf{frequenza cumulativa relativa} \( F_i \) della i-esima classe la somma
delle frequenze relative delle classi \( \pi _h \), con \( h \le i \), cioè:
\[
  F_i = \sum_{h=1}^{i} f_h = \frac{1}{n}N_i = \frac{1}{n}N_{i-1} + f_i
\] 
\[
  0 \le F_i \le 1, \; \text{per ogni}\; i \in I \quad e \quad F_i \le F_j, \; i<j
\] 

\section{Statistica descrittiva}
\subsection{Indici statistici}
Sono misure quantitative che fornicono informazioni sulla distribuzione di una certa
caratteristica.
\subsubsection{Indici di posizione o centralità}
Forniscono informazioni del valore attorno al quale si posizionano i dati. Consentono
di valutare l'ordine di grandezza della variabile aleatoria e aiutano a "localizzare"
la distribuzione. Sono espressi nella stessa unità di misura della variabile.

\vspace{1em}
\noindent Sia \( \underline{x} = (\tilde{x_1}, \ldots, \tilde{x_n}) \) un campione di dimensione \( n \).
\begin{itemize}
	\item \textbf{Media campionaria}: è il valore medio dei dati (baricentro dei dati):
    \[
      \overline{x} = \frac{1}{n} \sum_{j=1}^{n} \tilde{x}_j
    \] 
	\item \textbf{Moda campionaria}: \( m \) , valore che si ripete più frequentemente. Ci possono
	      essere più valori modali.

        \vspace{1em}
        \noindent Sia \( \underline{y} = (y_1, \ldots, y_n) \) il campione
	      ordinato (\( y_i \in \{\tilde{x_1}, \ldots, \tilde{x_n}\}  \) e \( y_i \le y_{i+1} \) )
	\item \textbf{Mediana campionaria}:\( M \): è il valore centrale del campione, una 
    volta ordinato.
	      \[
		      M = \begin{cases}
			      y_{\frac{n+1}{2}}                             & \text{se } n \text{ è dispari} \\
			      \frac{1}{2}(y_{\frac{n}{2}} + y_{\frac{n}{2}+1}) & \text{se } n \text{ è pari}
		      \end{cases}
	      \]
\end{itemize}

\subsubsection{Indici di dispersione}
Forniscono informazioni su quanto i dati si disperdono attorno ad un valore centrale. Sono:
\begin{itemize}
  \item \textbf{Range}: differenza tra il massimo e il minimo valore:
    \[
      r = \underset{j \in \{1, \ldots, n\} }{\max} \tilde{x}_j - \underset{j \in \{1, \ldots, n\} }{\min} \tilde{x}_j
    \] 
	\item \textbf{Scarto Quadratico Medio campionario}: misura la dispersione dei dati attorno alla media
	      \[
		      s'^2 = \frac{1}{n} \sum_{j=1}^{n} (\tilde{x_j} - \bar{x})^2
	      \]
	\item \textbf{Varianza campionaria}: misura la dispersione dei dati attorno alla media
	      \[
		      s^2 = \frac{1}{n-1} \sum_{j=1}^{n} (\tilde{x_j} - \bar{x})^2
	      \]
	\item \textbf{Deviazione standard campionaria}: misura la distanza dei dati attorno alla media
	      \[
		      s = \sqrt{s^2} = \sqrt{\frac{1}{n-1} \sum_{j=1}^{n} (\tilde{x_j} - \bar{x})^2}
	      \]
        Per interpretare la deviazione standard si possono definire 
        \textbf{valori usuali} di una variabile i valori del campione compresi tra:
        \begin{itemize}
          \item \textbf{Minimo valore "usuale"}: media campionaria - 2 deviazioni standard
          \item \textbf{Massimo valore "usuale"}: media campionaria + 2 deviazioni standard
        \end{itemize}

\end{itemize}

\subsubsection{Indici di forma}
Sia \( \underline{x} = (\tilde{x}_1, \ldots, \tilde{x}_n) \) un campione di dimensione 
\( n \).
\begin{itemize}
  \item \textbf{Asimmetria / Skewness}: misura la simmetria della distribuzione
    \[
      \gamma_1 = \frac{1}{n-1} \sum_{j=1}^{n} \left( \frac{\tilde{x}_j - \bar{x}}{s} \right)^3
    \] 
      \begin{itemize}
        \item \( \gamma_1 > 0 \): distribuzione asimmetrica a destra (con coda più lunga 
          a destra)
        \item \( \gamma_1 < 0 \): distribuzione asimmetrica a sinistra (con coda più
          lunga a sinistra)
        \item \( \gamma_1 = 0 \): distribuzione simmetrica
      \end{itemize}
  \item \textbf{Curtosi}: misura la "appuntitura" della distribuzione
    \[
      \gamma_2 = \frac{1}{n-1} \sum_{j=1}^{n} \left( \frac{\tilde{x}_j - \bar{x}}{s} \right)^4
    \]
    \begin{itemize}
      \item \( \gamma_2 = 3 \): curtosi della normale standard, (variabile di riferimento)
      \item \( \gamma_2 > 3 \): ci sono meno valori agli estremi di quanto aspettato, e
        di conseguenza si ha una minore dispersione dei dati. In tal caso la distribuzione
        risulta abbastanza appuntita
      \item \( \gamma_2 < 3 \): ci sono più valori agli estremi di quanto aspettato, e
        di conseguenza si ha una maggiore dispersione dei dati. In tal caso la distribuzione
        risulta piatta
    \end{itemize}
\end{itemize}

\subsubsection{Indici di posizione relativi}
Rappresentano indici di posizione, ma non centrali, bensì indici di posizionamento 
relativo.
\begin{itemize}
	\item \textbf{Percentili}: Se \( p \) è un numero tra \( 0 \) e \( 100 \), 
    il \textbf{percentile di ordine p} (o \( p \)-esimo percentile, se \( p \) è intero) 
    è il dato che delimita il primo \( p\% \) dei dati (ordinati) dai rimanenti dati.
	\item \textbf{Quartili}: Valori che separano i dati in quattro parti, una volta ordinati.
    \begin{figure}[H]
      \centering
      \begin{tikzpicture}
        \draw[thick, ->] (0,0) -- (12,0);
        \foreach \x in {1,2,3,4,5,6,7,8,9,10,11}
        \draw (\x cm,3pt) -- (\x cm,-3pt);

        \draw (0,-0.2) -- ++(0,-0.3) -- ++(2.95,0) node[midway, below]
          {Primo Quartile} -- ++(0,0.3);

        \draw (3,-0.2) -- ++(0,-0.3) -- ++(2.95,0) node[midway, below]
          {Secondo Quartile} -- ++(0,0.3);

        \draw (6,-0.2) -- ++(0,-0.3) -- ++(2.95,0) node[midway, below]
          {Terzo Quartile} -- ++(0,0.3);

        \draw (9,-0.2) -- ++(0,-0.3) -- ++(3,0) node[midway, below]
          {Quarto Quartile} -- ++(0,0.3);

      \end{tikzpicture}
    \end{figure}
    \[
      \underline{x} = (\tilde{x_1}, \ldots, \tilde{x_n}) \quad \text{campione di dimensione } n
    \]
    \[
      \underline{y} = (y_1, \ldots, y_n) \quad \text{campione ordinato}
    \]
    Il primo quartile è il valore che separa il \( 25\% \) inferiore dal \( 75\% \) superiore
    dei dati.
    \[
      Q_1 = \begin{cases}
        \frac{y_\frac{n}{4} + y_\frac{n}{4}+1}{2} & \frac{n}{4} \text{  intero}    \\
        y_{\lceil \frac{n}{4} \rceil}             & \frac{n}{4} \text{ non intero}
      \end{cases}
    \]
    Il secondo quartile è il 50-esimo percentile, ovvero la mediana. È il valore che separa
    il \( 50\% \) inferiore dal \( 50\% \) superiore dei dati.
    \[
      Q_2 = M = \begin{cases}
        \frac{y_{\frac{n}{2}} + y_{\frac{n}{2}+1}}{2} & \frac{n}{2} \text{  intero}    \\
        y_{\lceil \frac{n}{2} \rceil}                 & \frac{n}{2} \text{ non intero}
      \end{cases}
    \]
    Il terzo quartil è il 75-esimo percentile, ovvero il valore che separa il \( 75\% \)
    inferiore dal \( 25\% \) superiore dei dati.
    \[
      Q_3 = \begin{cases}
        \frac{y_{\frac{3n}{4}} + y_{\frac{3n}{4}+1}}{2} & \frac{3n}{4} \text{  intero}    \\
        y_{\lceil \frac{3n}{4} \rceil}                  & \frac{3n}{4} \text{ non intero}
      \end{cases}
    \]
    Lo scarto (o distanza interquartile) è la differenza tra il terzo e il primo quartile:
    \[
      IR = Q_3 - Q_1
    \]
\end{itemize}

\subsubsection{Box-Plot}
Fornisce informazioni sulla forma della distribuzione:
\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \begin{axis}[
      y=1.5cm,
      x=1.5cm,
      axis lines=left,
      axis line style={-},
      xmin=0,
      xmax=5,
      ymin=0,
      ymax=0.001,
      xtick={1,2,3,4},
      xticklabels={, \( Q_1 \), \( M \), \( Q_3 \),},
      ytick=\empty,
      xlabel={},
      ylabel={},
      xlabel style={below right},
      ylabel style={above left},
      x label style={at={(axis description cs:0.5,-0.1)},anchor=north},
      y label style={at={(axis description cs:-0.1,0.5)},anchor=south},
      title={Box-Plot},
      title style={at={(axis cs:2.5,1.5)}},
      clip=false
    ]
    \addplot[boxplot prepared={
      lower whisker=0.5,
      lower quartile=1,
      median=2.5,
      upper quartile=3,
      upper whisker=4
    }, color=black] coordinates {};

    % Draw dashed lines from whiskers and quartiles to x axis
    \draw[dashed] (axis cs:0.5,0.6) -- (axis cs:0.5,0) node[below, scale=0.7] {Minimo};
    \draw[dashed] (axis cs:1,0.6) -- (axis cs:1,0) node[below, scale=0.7] {$Q_1$};
    \draw[dashed] (axis cs:2.5,0.6) -- (axis cs:2.5,0) node[below, scale=0.7] {Mediana};
    \draw[dashed] (axis cs:3,0.6) -- (axis cs:3,0) node[below, scale=0.7] {$Q_3$};
    \draw[dashed] (axis cs:4,0.6) -- (axis cs:4,0) node[below, scale=0.7] {Massimo};
    \end{axis}
  \end{tikzpicture}
\end{figure}

\subsection{Outliers}
\begin{figure}[H]
	\begin{definition}
		Gli \textbf{Outliers} sono valori estremi, insolitamente grandi o piccoli, rispetto
		al resto dei dati.
		\[
			x \le Q_1 - 1.5 \cdot IR \quad \text{oppure} \quad x \ge Q_3 + 1.5 \cdot IR
		\]
	\end{definition}
\end{figure}
\label{D1}

\subsubsection{Outliers deboli}
Si dicono outliers deboli:
\[
	Q_1 - 3 \cdot IR < x \le Q_1 - 1.5 \cdot IR
\]
\begin{center}
	oppure
\end{center}
\[
	Q_3 + 1.5 \cdot IR < x \le Q_3 + 3 \cdot IR
\]

\subsubsection{Outliers forti}
Si dicono outliers forti:
\[
	x \le Q_1 - 3 \cdot IR
\]
\begin{center}
	oppure
\end{center}
\[
	x \ge Q_3 + 3 \cdot IR
\]
\subsubsection{Esempio}
Prendiamo in considerazione l'altezza degli studenti
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		Indice                   & Valore \\
		\hline
		min                      & 146    \\
		\( Q_1 \)                & 163    \\
		\( Q_2 = M \)            & 168    \\
		\( Q_3 \)                & 175    \\
		max                      & 196    \\
		\( IR \)                 & 12     \\
		\( Q_1 - 1.5 \cdot IR \) & 2.5    \\
		\( Q_3 + 1.5 \cdot IR \) & 6.5    \\
		\( Q_1 - 3 \cdot IR \)   & 1      \\
		\( Q_3 + 3 \cdot IR \)   & 8      \\
		\hline
	\end{tabular}
\end{table}
\label{D2}

\section{Statistica descrittiva bivariata}
\subsection{Confronto tra due variabili}
Prendiamo ad esempio l'età degli uomini e delle donne su una popolazione senza outliers.
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Indice                  & Uomini & Donne \\
		\hline
		media                   & 21.41  & 20.83 \\
		mediana                 & 21.00  & 20.70 \\
		range                   & 6.20   & 6.20  \\
		scarto quadratico medio & 2.56   & 1.81  \\
		scarto quadratico medio & 2.56   & 1.81  \\
		deviazione standard     & 1.60   & 1.35  \\
		asimmetria              & 0.66   & 1.09  \\
		curtosi                 & 2.62   & 3.99  \\
		\hline
	\end{tabular}

\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|}
		\hline
		Indice                   & Uomini & Donne \\
		\hline
		min                      & 19.10  & 19.10 \\
		\( Q_1 \)                & 20.30  & 19.80 \\
		\( Q_2 = M \)            & 21.00  & 20.70 \\
		\( Q_3 \)                & 22.40  & 21.40 \\
		max                      & 25.30  & 25.30 \\
		\( IR \)                 & 3.30   & 2.30  \\
		\( Q_1 - 1.5 \cdot IR \) & 15.35  & 16.35 \\
		\( Q_3 + 1.5 \cdot IR \) & 27.35  & 24.85 \\
		\( Q_1 - 3 \cdot IR \)   & 10.40  & 12.90 \\
		\( Q_3 + 3 \cdot IR \)   & 32.30  & 28.30 \\
		\hline
	\end{tabular}
\end{table}
\label{D3}

\begin{enumerate}
	\item C'è \textbf{evidenza statistica} che le distribuzioni siano diverse?

	\item Che l'età media sia uguale? Che quella delle donne sia minore?
\end{enumerate}

\subsection{Relazione tra 2 variabili}
\begin{itemize}
	\item \textbf{Correlazione}: Associazione \textbf{lineare} tra 2 variabili. La forza
	      dell'associazione è data dal \textbf{coefficiente di correlazione}.
	\item \textbf{Regressione}: dipendenza di una variabile (dipendente) da
	      un’altra variabile (indipendente)
\end{itemize}

\noindent Sia \( (\underline{x}, \underline{y}) = ((\tilde{x}_1, \tilde{y}_1), \ldots (\tilde{x}_n, \tilde{y}_n)) \)
un campione di dimensione \( n \) di due misure \( x \) ed \( y \), con medie campionarie
\( \bar{x} \) e \( \bar{y} \), deviazioni standard campionarie \( (s_x, s_y) \).
\[
	\bar{x} = \frac{1}{n} \sum_{i=1}^{n} \tilde{x}_i
\]
\[
	\bar{y} = \frac{1}{n} \sum_{i=1}^{n} \tilde{y}_i
\]
\[
	s_x = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (\tilde{x}_i - \bar{x})^2}
\]
\[
	s_y = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (\tilde{y}_i - \bar{y})^2}
\]
Il coefficiente di correlazione campionario è definito come:
\[
	\rho_n \stackrel{\Delta}{=} \frac{\sum_{i=1}^{n} (\tilde{x}_i - \bar{x})
		(\tilde{y}_i - \bar{y})}{\sqrt{\sum_{i=1}^{n} (\tilde{x}_i - \bar{x})^2
			\sum_{i=1}^{n} (\tilde{y}_i - \bar{y})^2}}
\]
Il risultato sarà un numero compreso tra \( -1 \) e \( 1 \):
\[
	| \rho_n | \le 1
\]
Questo indice misura il grado di dipendenza lineare tra le due variabili.

\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\( | \rho_n | \)      & Grado di correlazione tra \( \underline{x}\;e\;\underline{y} \) \\
		\hline
		\( \rho_n = -1 \)     & massima correlazione lineare inversa                            \\
		\( -1 < \rho_n < 0 \) & correlazione inversa                                            \\
		\( \rho_n = 0 \)      & assenza di correlazione                                         \\
		\( 0 < \rho_n < 1 \)  & correlazione diretta                                            \\
		\( \rho_n = 1 \)      & massima correlazione lineare diretta                            \\
		\hline
	\end{tabular}
\end{table}
Sono indici qualitativi:
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|}
		\hline
		\( \rho_n \)                    & Grado di correlazione tra \( \underline{x}\;e\;\underline{y} \) \\
		\hline
		\( | \rho_n | \le 0.5 \)        & scarsa correlazione                                             \\
		\( 0.5 < | \rho_n | \le 0.75 \) & correlazione moderata                                           \\
		\( 0.75 < | \rho_n | \le 0.9 \) & correlazione buona                                              \\
		\( | \rho_n | > 0.9 \)          & correlazione molto buona                                        \\
		\hline
	\end{tabular}
\end{table}

\subsection{Regressione}
La regressione lineare è un modello matematico che cerca di esprimere una variabile.
Per ipotesi riteniamo che due variabili siano legate da una relazione del tipo \( y = g(x) \)
\begin{enumerate}
	\item I dati accoppiati \( (x,y) \) costituiscono un campione di dati quantitativi
	\item Dallo scatter plot possiamo ipotizzare che nella \textbf{popolazione} ci sia una
	      relazione lineare del tipo:
	      \[
		      y_i = \beta_0 + \beta_1 x_i + \varepsilon_i
	      \]
	      dove \( \varepsilon_i \) è l'errore casuale, con distribuzione a campana
	      \begin{figure}[H]
		      \centering
		      \begin{tikzpicture}
			      % bell curve
			      \begin{axis}[
				      xlabel={x},
				      ylabel={Densità}
				      ]
				      \addplot[domain=-3:3, samples=100, color=red]{1/(sqrt(2*pi))*exp(-x^2/2)};
			      \end{axis}
		      \end{tikzpicture}
	      \end{figure}
	\item Cerchiamo di individuare l'equazione della \textbf{curba di regressione relativa
		      del campione}:
	      \[
		      \hat{y}_i = a + bx_i
	      \]
\end{enumerate}

\subsubsection{Determinazione dei coefficienti della retta di regressione}
L'obiettivo è quello di determinare i coefficienti \( a \) e \( b \) in modo ottimale,
affinchè la retta di regressione \( \hat{y}_i = a + bx_i \) sia il più possibile vicina
ai punti \( (x_i, y_i) \) del campione.

Si determina quindi l'equazione generica della curva interpolante stimando i parametri in
modo da rendere \textbf{minima} la distanza al quadrato dei punti osservati dalla curva.
\[
  \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} (y_i - a - bx_i)^2
\] 
Equazioni normali:
\[
  \begin{cases}
    \sum_{i=1}^{n} y_i = na + b \sum_{i=1}^{n} x_i \\
    \sum_{i=1}^{n} x_i y_i = a \sum_{i=1}^{n} x_i + b \sum_{i=1}^{n} x_i^2
  \end{cases}
\]

\subsection{Riassunto}
\begin{itemize}
  \item Dato \textbf{un campione}: abbiamo determinato una \textbf{stima} di alcuni
    parametri (media, deviazione standard, varianza, quartili, ...), una stima della
    distribuzione (frequqnze relative) con grafici (istogramma [frequenza relativa],
    diagrammi [area = frequenza relativa], boxplot [quartili, outliers])
  \item Dati \textbf{due campioni}: abbiamo determinato una \textbf{stima} di alcuni
    parametri (media, deviazione standard, varianza, quartili, ...) ed una stima della
    distribuzione (frequenze relative) con grafici (scatter plot, retta di regressione,
    coefficiente di correlazione) e abbiamo fatto un \textbf{confronto}.

    Abbiamo determinato una stima della \textbf{correlazione} e la retta di regressione lineare.
    \[
      \rho_n = \text{coeff. di correlazione} \quad \rho_n \approx 1
    \] 
\end{itemize}

\noindent Per capire se le informazioni tratte dal campione sono statisticamente significative
si fa riferimento alla \textbf{statistica inferenziale}. Ma bisogna essere ingrado di
parlare di probabilità e di distribuzioni teoriche (modelli probabilistici).

\section{Probabilità}
\subsection{Esperimenti aleatori}
Un fenomeno \textbf{casuale}, o aleatorio, è un fenomeno \textbf{osservabile}, ma non
prevedibile. Cioè conoscendo i dati iniziali e le leggi, non possiamo prevederne il 
risultato. Ciò che invece possiamo conoscere è l'insieme di tutti i possibili risultati.
\begin{itemize}
  \item \textbf{Fenomeno deterministico}: Dati + Leggi = Conoscenza
  \item \textbf{Fenomeno non deterministico}: Dati + Leggi = Non Conoscenza
\end{itemize}

\noindent Alcuni esempi di esperimenti sono:
\begin{itemize}
  \item Consideriamo tre figli di una stessa coppia. Controlliamo il sesso dei tre.
  \item Lancio un dado.
    Controllo il numero che esce. 
  \item Lancio 2 dadi.
    Controllo i numeri che escono. 
  \item Considero i piselli so che possono avere il baccello verde o giallo e il fiore
    bianco o viola.
    Ne estraggo uno a caso. Che caratteristiche ha? 
  \item Sono ad un call center.
    Conto il numero di telefonate
    che arrivano in un intervallo di tempo  
  \item Misuro all’altezza di un uomo
    di 40 anni italiano 
\end{itemize}

\subsection{Spazio campionario ed eventi}
È l'insieme di tutti i possibili risultati di un esperimento casuale:
\[
  \Omega = \{\omega_1, \omega_2, \ldots, \omega_n\}
\] 
Uno dei possibili risultati dell'esperimento si chiama \textbf{Evento elementare}:
\[
  \{\omega_i\},\quad i = 1, \ldots, n 
\] 
L'\textbf{Evento} è un sottoinsieme dello spazio campione \( A \subset \Omega \) in cui
sono contenuti alcuni dei possibili eventi elementari, quelli favorevoli all'evento
considerato.
\subsubsection{Esperimento 1: Lancio di un dado}
Prendiamo in considerazione il lancio di un dado:
\[
\text{Lo spazio dei campioni è: } \quad \Omega = \{1, 2, 3, 4, 5, 6\}
\] 
I possibili eventi sono:
\begin{enumerate}
  \item[A =] Il risultato del lancio è 1
  \item[B =] Il risultato del lancio è dispari
  \item[C =] Il risultato del lancio è maggiore di 4
  \item[D =] Il risultato del lancio è dispari non maggiore di 4
  \item[E =] Il risultato del lancio è pari
  \item[F =] Il risultato del lancio è 7
  \item[G =] Il risultato del lancio è tra 1 e 6
\end{enumerate}
\[
  A = \{1\} \quad B = \{1, 3, 5\} 
\] 
\[
  C = \{1, 2, 3, 4\} \quad D = \{1, 3, 5\} \bigcap \{1, 2, 3, 4\} = B \bigcap C = \{1,3\} 
\] 
\[
  E = \{2, 4, 6\} = \Omega \setminus B = \overline{\{1, 3, 5\} } = \overline{\tilde{B}}
\]
\[
  F = \{7\} = \overline{\Omega} = \emptyset
\] 
\[
  G = \{1, 2, 3, 4, 5, 6\} = \Omega 
\] 

\subsubsection{Esperimento 2: Lancio di 2 dadi}
Prendiamo in considerazione il lancio di 2 dadi:
\[
  \Omega_2 = \{1, 2, 3, 4, 5, 6\} \times \{1, 2, 3, 4, 5, 6\} = \{(1,1), (1,2), \ldots, (6,6)\}
\] 

\subsubsection{Esperimento 3: Sesso dei nascituri}
Consideriamo 3 figli di una stessa coppia. Controlliamo il sesso dei tre.

Se considero una \textbf{singola nascita} lo spazio dei campioni è:
\[
\Omega = \{M, F\}
\] 
Quindi si hanno due possibili eventi elementari:
\[
\{\text{M}\}, \{\text{F}\}
\]
Se invece considero \textbf{tre nascite} lo spazio dei campioni è:
\[
\Omega = \{(\omega_1, \omega_2, \omega_3) \quad \omega_i \in \Omega\}
\]
quindi è costituito da tutte le \textbf{terne} ordinate di maschi e femmine.
\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    1° Figlio & 2° Figlio & 3° Figlio \\
    \hline
    M         & M         & M         \\
    M         & M         & F         \\
    M         & F         & M         \\
    M         & F         & F         \\
    F         & M         & M         \\
    F         & M         & F         \\
    F         & F         & M         \\
    F         & F         & F         \\
    \hline
  \end{tabular}
\end{table}
\noindent Ogni terna rappresenta un \textbf{evento elementare}.

\subsubsection{Caratteristiche degli esperimenti 1-3}
\begin{itemize}
  \item Lo spazio dei campioni è finito
  \item Gli eventi sono tutte le parti di \( \Omega \), cioè tutti i possibili sottoinsiemi
    di \( \Omega \)
\end{itemize}

\subsubsection{Esperimento 4: Tempo di attesa}
Sono ad un call center e conto il numero di telefonate che arrivano in un intervallo di tempo.

\noindent Lo spazio dei campioni è:
\[
  \Omega = \{0, 1, 2, 3, \ldots\}
\] 

\textbf{Caratteristiche}:
\begin{itemize}
  \item Lo spazio dei campioni è \textbf{infinito numerabile}
  \item Gli eventi sono tutte le parti di \( \Omega \), cioè tutti i possibili sottoinsiemi
    di \( \Omega \)
\end{itemize}

\subsubsection{Esperimento 5: Misure}
Misuro l’altezza di un uomo di 40 anni italiano.

\noindent Lo spazio dei campioni è:
\[
  \Omega \subseteq \mathbb{R}
\] 

\textbf{Caratteristiche}:
\begin{itemize}
  \item Lo spazio dei campioni è un sottoinsieme di \( \mathbb{R} \), quindi è
    \textbf{infinito non numerabile}
  \item Gli eventi sono tutti i sottointervalli di \( \mathbb{R} \), le loro unioni e le 
    loro intersezioni
\end{itemize}

\subsubsection{Tipi di esperimenti}
Gli esperimenti possono essere di diversi tipi:
\begin{itemize}
  \item \textbf{Misure di conteggio}
  \item \textbf{Misure continue}
\end{itemize}

\subsubsection{Tipi di eventi}
\begin{itemize}
  \item \textbf{Evento certo}:\\
    È un evento che si verifica sempre, cioè \( A = \Omega \), ad esempio il lancio di
    un dato ha sempre un risultato certo.
\end{itemize}

\subsection{Spazio campionario e insieme degli eventi}
\begin{figure}[H]
  \begin{definition}
    Lo \textbf{spazio dei campioni \( \Omega \) } è l'insieme di tutti i possibili esiti 
    (risultati). La cardinalità di uno spazio dei campioni può esssere finita, infinita
    numerabile e infinita non numerabile.
    \[
    \Omega = \{\omega_1, \omega_2, \ldots, \omega_n\} \quad \text{oppure} \quad
    \Omega \subseteq \mathbb{R}
    \] 
  \end{definition}
\end{figure}
\begin{figure}[H]
  \begin{definition}
    L'\textbf{insieme degli eventi \( \mathcal{A} \) } è un insieme \textbf{finito} di
    parti di \( \Omega \) tali che sia un'algebra, cioè tale che:
    \begin{enumerate}
      \item \( \Omega \in \mathcal{A} \)
      \item Unione di eventi è un evento
        \[
          A,B \in \mathcal{A} \Rightarrow A \cup B \in \mathcal{A}
        \] 
      \item se \( A,B \in \mathcal{A} \), allora \( A \setminus B \in \mathcal{A}  \) 
        \[
        \Downarrow
        \] 
        \[
          A \in \mathcal{A} \Rightarrow A^c = \Omega \setminus A \in \mathcal{A}
        \] 
    \end{enumerate}
  \end{definition}
\end{figure}

\begin{figure}[H]
  \begin{definition}
    \( \sigma  \)-algebra \( \mathcal{F} \) è un insieme qualsiasi \( \mathcal{F} \) di
    parti di \( \Omega \) tali che:
    \begin{enumerate}
      \item \( \Omega \in \mathcal{F} \)
      \item sia \( \{A_n\}  \) 
        TODO
    \end{enumerate}
  \end{definition}
\end{figure}

\subsubsection{Esempi}
\begin{figure}[H]
  \begin{example}
    Lancio il dado e controllo che numero esce
    \[
      \mathcal{A} = \mathcal{P}(\Omega) =
    \] 
    \[
      = \big\{ \{1\} ,\{2\} ,\{3\}, \{4\}, \{5\}, \{6\},
      \]
      \[
      \{1,2\}, \{1,3\}, \{1,4\}, \{1,5\}, \{1,6\},
    \]
    \[
      \{2,3\}, \{2,4\}, \{2,5\}, \{2,6\},
    \]
    \[
      \ldots
    \]
    \[
      \{1,2,3\}, \{1,2,4\}, \{1,2,5\}, \{1,2,6\},\ldots
    \]
    \[
      \{1,2,3,4\}, \{1,2,3,5\}, \{1,2,3,6\},\ldots
    \]
    \[
      \{1,2,3,4,5\}, \{1,2,3,4,6\},\ldots
    \]
    \[
    \{1,2,3,4,5,6\} = \Omega, \emptyset \big\}
    \] 
  \end{example}
\end{figure}

\section{Probabilità}
La probabilità di un evento \( A \in \mathcal{A} \) rappresenta una misura di quanto
ci si aspetta che si verifichi l'evento \( A \).

Calcolare le probabilità non significa "prevedere il futuro", ma trovare come distribuire
un maggiore o minore \textbf{grado di fiducia} tra i vari possibili modi in cui si potrà
presentare un certo fenomeno aleatorio.

\begin{figure}[H]
  \begin{define}
    L'\textbf{ipotesi dei modelli} è lo spazio dei campioni \textbf{finito} \( \Leftrightarrow
    card(\Omega) = n < \infty\) 

    \textbf{Eventi equiprobabili}:
    \[
    P(\omega_i) = P(\omega_j), \quad i,j \in \{1, \ldots, n\} 
    \] 
  \end{define}
\end{figure}

La probabilità di un evento \( A \in \mathcal{A} \) si calcola come:
\[
P(A) = \frac{\text{casi favorevoli ad \( A \) }}{\text{casi possibili}} = \frac{card(A)}{card(\Omega)}
\] 

\subsection{Probabilità degli esperimenti 1-2}
\subsubsection{Esperimento 1: Lancio di un dado}
\[
\Omega_1 = \{1, 2, 3, 4, 5, 6\}
\] 
\[
P(\{i\} ) = \frac{\text{casi favorevoli}}{\text{casi possibili}} = \frac{card(\{i\} )}
{card(\Omega)} = \frac{1}{6}, \quad i = 1, \ldots, 6
\] 

\subsubsection{Esperimento 2: Lancio di 2 dadi}
\[
\Omega_2 = \{1, 2, 3, 4, 5, 6\} \times \{1, 2, 3, 4, 5, 6\} = \{(1,1), (1,2), \ldots, (6,6)\}
\]
\[
  P(A) = \frac{\text{casi favorevoli ad \( A \) }}{\text{casi possibili}} = \frac{card(A)}{card(\Omega)}
  = \frac{11}{36}
\]
\subsubsection{TODO altri esperimenti}

\subsection{Definizione frequentista di probabilità}
\begin{figure}[H]
  \begin{define}
    L'ipotesi dei modelli deve essere ripetibile all'esperimento, quindi bisogna avere
    tante prove ripetuto (nelle stesse condizioni) ed indipendenti
  \end{define}
\end{figure}

La probabilità di un evento \( A \in \mathcal{A} \), fatte \( n \) prove:
\[
  P(A) = \frac{\text{numero di occorrenze di \( A \) }}{n} = f_n(A)
\] 
Si basa sulla \textbf{legge empirica del caso} che sintetizza una regolarità osservabile
sperimentalmente.

\subsection{Definizione soggettiva di probabilità}
È la misura del grado di fiducia che un individuo \textbf{coerente} assegna al verificarsi
di un dato evento in base alle sue \textbf{conoscenze}

Probabilità di un evento \( A \in \mathcal{A} \):
\[
  P(A) = \frac{\text{posta}}{\text{{vincita}}} = \frac{P}{V}
\] 
In breve, "se ci credo, pago"

\section{Assiomi di Kolmogorov}
L’impostazione assiomatica permette a Kolmogorov di non esplicitare esattamente come
valutare la probabilità (lasciando quindi la libertà di seguire l’approccio più adatto al caso in
esame), ma di limitarsi solo a indicare quali sono le regole formali che una misura di
probabilità deve soddisfare per poter essere dichiarata tale.

\subsection{Assiomi}
\subsubsection{Caso finito}
\begin{figure}[H]
  \begin{definition}
    \[
      (\Omega, \mathcal{A}, P)
    \] 
    \begin{enumerate}
      \item[$P_1.$] \( P(\Omega) = 1 \) 
      \item[$P_2.$] sia \( A,B \in \mathcal{A} \) disgiunti, t.c
        \[
          A \cap B = \emptyset 
        \] 
        allora
        \[
          P(A \cup B) = P(A) + P(B)
        \] 
        (additività finita)
    \end{enumerate}
  \end{definition}
\end{figure}

\subsubsection{Caso generale}
\begin{figure}[H]
  \begin{definition}
    \[
      (\Omega, \mathcal{A}, P)
    \] 
    \begin{enumerate}
      \item[$P_1.$] \( P(\Omega) = 1 \) 
      \item[$P_2^\sigma.$] sia \( \{A_n\}_n, A_n \in \mathcal{F}  \) disgiunti t.c.
        \[
          A_i \cap A_j = \emptyset, \quad i \neq j
        \] 
        allora
        \[
          P\left( \bigcup_{i=1}^{\infty} A_i \right) = \sum_{i=1}^{\infty} P(A_i)
        \] 
    \end{enumerate}
  \end{definition}
\end{figure}
\end{document}
