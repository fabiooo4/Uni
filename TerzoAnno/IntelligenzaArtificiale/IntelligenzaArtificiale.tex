\documentclass[a4paper]{article}
\usepackage{import}
\input{../../preamble.sty}

\begin{document}

\input{title.tex}

\tableofcontents
\pagebreak

\section{Introduzione}
Nel 1950 Alan Turing pubblica un articolo intitolato "Computing Machinery and Intelligence" in cui propone
un esperimento per determinare se una macchina può essere considerata intelligente. L'esperimento, noto
come "test di Turing", coinvolge un interrogatore umano che comunica con due entità nascoste: una macchina
e un essere umano. L'interrogatore deve fare domande a entrambe le entità e, basandosi sulle risposte,
deve determinare quale delle due è la macchina. Se l'interrogatore non riesce a distinguere tra le risposte
della macchina e quelle dell'essere umano, la macchina è considerata intelligente.

\vspace{1em}
\noindent
In futuro l'attenzione si è spostata sulla ricerca di metodi per risolvere problemi che richiedono intelligenza
umana, utilizzando algoritmi e modelli matematici fino ad arrivare alle reti neurali e intelligenza artificiale.

\begin{definition}
  L'intelligenza artificiale è una disciplina che studia come \textbf{simulare} l'intelligenza umana in
  scenari complessi
\end{definition}

\subsection{Tipi di intelligenza artificiale}
\subsubsection{Autonomous agents}
Sono sistemi che percepiscono l'ambiente e agiscono in modo autonomo per raggiungere obiettivi specifici.

\subsubsection{Data analysis}
Utilizzo di algoritmi per analizzare grandi quantità di dati e estrarre informazioni utili e correlazioni
complesse.

\subsubsection{Machine Learning}
È lo sviluppo di algoritmi che permettono a dei modelli di apprendere dai dati
di esempio e migliorare le loro prestazioni nel tempo senza essere esplicitamente programmati.
Ad esempio riconoscimento di immagini.

L'apprendimento automatico è diviso in tre categorie principali:
\begin{itemize}
  \item \textbf{Unsupervised learning}: il modello viene addestrato su un insieme di dati non etichettati,
  dove l'obiettivo è scoprire strutture nascoste o pattern nei dati senza avere risposte corrette predefinite.
\item \textbf{Supervised learning}: il modello viene addestrato su un insieme di dati etichettati,
  dove ogni esempio di input è associato a una risposta corretta. L'obiettivo è che il modello impari a
  mappare gli input alle risposte corrette.
  \item \textbf{Reinforced learning}: il modello impara attraverso interazioni con l'ambiente, ricevendo
  ricompense o penalità in base alle azioni intraprese. L'obiettivo è massimizzare la ricompensa totale nel
  tempo.
\end{itemize}

\subsubsection{Time series analysis}
L'analisi delle serie temporali è un'area dell'apprendimento automatico che si concentra sull'analisi di dati
collezionati nel tempo. Le serie temporali sono sequenze di dati misurati a intervalli regolari, come
temperatura giornaliera, prezzi delle azioni o dati di vendita mensili. L'obiettivo dell'analisi delle
serie temporali è identificare pattern, tendenze e stagionalità nei dati per fare previsioni future.

\vspace{1em}
\noindent
Gli approcci comuni per l'analisi delle serie temporali includono:
\begin{itemize}
  \item \textbf{Riconoscimento di anomalie e cause}:
    è un processo di identificazione di dati o eventi che si discostano
    significativamente dal comportamento normale o atteso. Queste anomalie possono indicare problemi,
    errori o situazioni insolite che richiedono attenzione.

  \item \textbf{Generative transformers}:
    sono una classe di modelli che permettono di predirre il prossimo elemento in una
    sequenza di dati partendo dagli elementi precedenti, come ad esempio la parola successiva in una frase o il
    pixel successivo in un'immagine. Si sfrutta il concetto di \textbf{attenzione} per pesare l'importanza
    relativa delle diverse parti della sequenza di input durante la generazione dell'output.
\end{itemize}

\subsubsection{Intelligent Agents}
Un agente intelligente è un sistema che percepisce l'ambiente circostante attraverso sensori e agisce su
l'ambiente per raggiungere un obiettivo specifico. Gli elementi chiave di un agente intelligente includono:
\begin{itemize}
  \item \textbf{Performance measure}: misura il successo dell'agente nel raggiungere i suoi obiettivi
  \item \textbf{Rationality}: l'agente deve agire in modo da massimizzare la sua performance measure attesa
\end{itemize}

\subsection{Markov Decision Process (MDP)}
Un MDP è un modello matematico utilizzato per rappresentare problemi di decisione sequenziali. Gli elementi
principali sono:
\begin{itemize}
  \item \textbf{State}: rappresenta l'ambiente in un dato momento
  \item \textbf{Actions}: insieme delle azioni che l'agente può intraprendere
  \item \textbf{Transition model}: effetto che le azioni hanno sull'ambiente (potrebbero essere parzialmente incognite
    \[
      T: (state, action) \to next\_state
    \] 
  \item \textbf{Reward}: valore \textbf{immediato} dell'esecuzione di un'azione
    \[
      R: (state, action, next\_state) \to real\_number
    \] 
  \item \textbf{Policy}: strategia che l'agente utilizza per decidere quale azione intraprendere in ogni stato
    con l'obiettivo di massimizzare la ricompensa totale attesa nel tempo
    \[
      \pi: (state) \to action
    \] 
\end{itemize}

\subsection{Generative AI}
L'intelligenza artificiale generativa si riferisce a una classe di modelli di intelligenza artificiale
che sono in grado di generare nuovi contenuti, come testo, immagini, musica o video, a partire da dati di
addestramento. Questi modelli hanno miliardi di parametri e sono \textbf{preaddestrati} su grandi quantità
di dati. In sostanza questi modelli "predicono il futuro" basandosi sui dati su cui sono stati addestrati e
un \textbf{propmpt} (input dell'utente).

\section{Agenti e ambiente}
Gli agenti includono umani, robot, softbot, termostati ecc... La funzione dell'agente
mappa lo storico di percezioni in azioni:
\[
  f: \mathcal{P}^* \mapsto \mathcal{A}
\] 
Il programma dell'agente è eseguito su architettura fisica per produrre la funzione \( f \).
\begin{example}
  Un esempio potrebbe essere un insieme di stanze \( \{A, B\}  \) e un robot aspirapolvere che può
  percepire la sua posizione e il contenuto della stanza. L'agente potrebbe quindi percepire
  \( [A, Sporco] \) se ci fosse dello sporco nella stanza A. Le azioni potrebbero essere
  di movimento o pulizia. Tutto questo dipende dalla squenza di percezioni, ad esempio 
  in una tabella:
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
      \hline
      Percezione & Azione \\
      \hline
      \( [A, Pulito] \) & Vai a B \\
      \( [A, Sporco] \) & Pulisci \\
      \( [B, Pulito] \) & Vai ad A \\
      \( [B, Sporco] \) & Pulisci \\
      \( [A, Pulito], [A, Pulito] \) & Vai a B \\
      \( [A, Pulito], [A, Sporco] \) & Pulisci \\
      \hline
    \end{tabular}
    \caption{Esempio di tabella di percezioni e azioni}
  \end{table}
  \noindent
  Non possiamo dire se questa è una funzione corretta perchè non abbiamo una
  \textbf{performance measure} che ci dica se l'agente sta facendo un buon lavoro.
\end{example}

\begin{definition}
  Se un agente ha \( \left| \mathcal{P} \right|  \) possibili percezioni, allora al tempo
  \( T \) avrà:
  \[
    \sum_{t=1}^{T} \left| \mathcal{P} \right|^t
  \] 
\end{definition}
\noindent
Se lo storico di percezioni è irrilevante, cioè se ad ogni percezione è associata un'azione
la funzione viene chiamata \textbf{Reflex}.

\subsection{Razionalità}
Per definire l'intelligenza di un agente si utilizza una misura di performance che
valuta la sequenza di percezioni.
\begin{example}
  Tornando all'esempio del robot aspirapolvere si potrebbero assegnare i seguenti
  punteggi:
  \begin{itemize}
    \item Un punto per ogni stanza pulita per ogni unità di tempo
    \item Meno un punto per ogni mossa
    \item Penalizzazione per ogni stanza sporca
  \end{itemize}
\end{example}

\begin{example}
  Un altro esempio è il seguente ambiente:
  \begin{itemize}
    \item Ci sono 3 stanze \( (A,B,C) \) e due robot \( (r_1, r_2) \) 
    \item \( r_1 \) può sorvegliare solo \( A \) e \( B \) e \( r_2 \) solo \( B \) e \( C \)
    \item \( r_1 \) inizia dalla stanza \( A \) e \( r_2 \) dalla \( C \)
    \item Il tempo di percorrenza tra le stanze è 0
    \item Performance measure: minimizza il tempo in cui una stanza non è sorvegliata,
      cioè il tempo totale in cui una stanza non è visitata da nessun robot
  \end{itemize}

  Un possibile comportamento razionale potrebbe essere il seguente (alternata):
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c||c|c|}
      \hline
      Stato & \( A \) & \( B \) & \( C \) & Tempo  \\
      \hline
      \( [A, C] \) & 0 & 1 & 0 & 1 \\
      \( [B, C] \) & 1 & 0 & 0 & 2 \\
      \( [A, C] \) & 0 & 1 & 0 & 3 \\
      \( [A, B] \) & 0 & 0 & 1 & 4 \\
      \hline
      Average idleness & \( \frac{1}{4} \)  & \( \frac{1}{2} \)  & \( \frac{1}{4} \)  & Tot: \( \frac{1}{3} \)  \\
      \hline
    \end{tabular}
  \end{table}
  \noindent
  Un altro comportamento potrebbe essere (fissata):
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c||c|c|}
      \hline
      Stato & \( A \) & \( B \) & \( C \) & Tempo  \\
      \hline
      \( [A, C] \) & 0 & 1 & 0 & 1 \\
      \( [B, C] \) & 1 & 0 & 0 & 2 \\
      \( [A, C] \) & 0 & 1 & 0 & 3 \\
      \( [B, C] \) & 1 & 0 & 0 & 4 \\
      \hline
      Average idleness & \( \frac{1}{2} \)  & \( \frac{1}{2} \)  & \( 0 \)  & Tot: \( \frac{1}{3} \)  \\
      \hline
    \end{tabular}
  \end{table}
  \noindent
  Entrambi i comportamenti hanno la stessa performance measure, ma il primo è migliore
  del secondo perchè penalizza meno una singola stanza rispetto alle altre. Per capirlo
  bisogna non solo minimizzare la performance measure, ma anche minimizzare la varianza.
\end{example}

\subsection{PEAS}
Per progettare un agente intelligente bisogna definire l'ambiente in cui opera:
\begin{itemize}
  \item \textbf{Performance measure}: come viene valutato il successo dell'agente
  \item \textbf{Environment}: il contesto in cui l'agente opera
  \item \textbf{Actuators}: i mezzi attraverso cui l'agente agisce sull'ambiente
  \item \textbf{Sensors}: i mezzi attraverso cui l'agente percepisce l'ambiente
\end{itemize}

\begin{example}
  Prendiamo ad esempio un taxi automatico, il PEAS potrebbe essere:
  \begin{itemize}
    \item Performance measure:
      \begin{itemize}
        \item Soddisfazione del cliente
        \item Sicurezza
        \item Efficienza del carburante
        \item Rispetto delle leggi stradali
      \end{itemize}
    \item Environment:
      \begin{itemize}
        \item Traffico stradale
        \item Condizioni meteorologiche
        \item Segnali stradali
        \item Pedoni e altri veicoli
      \end{itemize}
    \item Actuators:
      \begin{itemize}
        \item Volante
        \item Acceleratore
        \item Freni
        \item Indicatori di direzione
      \end{itemize}
    \item Sensors:
      \begin{itemize}
        \item Telecamere
        \item Lidar
        \item Radar
        \item Sensori di velocità
        \item GPS
      \end{itemize}
  \end{itemize}
\end{example}

\section{Tipi di ambienti}
Gli ambienti possono essere classificati in base a diverse caratteristiche:
\begin{itemize}
  \item \textbf{Osservabile}: se l'agente può percepire completamente lo stato dell'ambiente
    in ogni momento
  \item \textbf{Deterministico}: se l'azione dell'agente determina in modo univoco il prossimo stato
    dell'ambiente
  \item \textbf{Episodico}: se l'esperienza dell'agente è divisa in episodi indipendenti,
    cioè l'azione in un episodio non influisce sugli episodi successivi
  \item \textbf{Statico}: se l'ambiente non cambia mentre l'agente sta prendendo una
    decisione
  \item \textbf{Discreto}: se l'insieme di stati, azioni e percezioni è finito o numerabile
  \item \textbf{Singolo agente}: se l'agente opera da solo nell'ambiente senza la presenza
    di altri agenti
\end{itemize}
\begin{example}
  Prendiamo ad esempio i seguenti ambienti provando a classificarli:
  \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
      \hline
      & Crossword & Robo-selector & Poker & Taxi \\
      \hline
      Osservabile & Sì & Parziale & Parziale & Parziale \\
      Deterministico & Sì & No & No & No \\
      Episodico & No & Sì & No & No \\
      Statico & Sì & No & Sì & No \\
      Discreto & Sì & No & Sì & No \\
      Singolo agente & Sì & Sì & No & No \\
      \hline
    \end{tabular}
  \end{table}
\end{example}
Il tipo di ambiente cambia radicalmente la soluzione del problema:
\begin{itemize}
  \item \textbf{Deterministico, completamente osservabile}: Single-state problem
  \item \textbf{Completamente non osservabile}: Conformant problem, l'agente non sa in che
    stato si trova, ma potrebbe trovare una soluzione
  \item \textbf{Non deterministico e/o parzialmente osservabile}: Contingency problem,
    l'agente deve prevedere le possibili situazioni future e agire di conseguenza
  \item \textbf{Spazio degli stati sconosciuto}: Exploration problem, l'agente deve esplorare
    l'ambiente per scoprire gli stati e le azioni disponibili
\end{itemize}

\subsection{Agenti di problem solving}
È una forma ristretta di agenti che formulato un problema e un obiettivo partendo da uno stato
cerca una soluzione ignorando le percezioni, siccome ci si trova in un single-state problem.
Questo si chiama Offline problem solving perchè l'agente ha completa conoscenza dell'ambiente.
Online problem solving è quando l'agente non ha completa conoscenza dell'ambiente.
\begin{example}
  Il seguente è un esempio di problem solving agent:
  \begin{lstlisting}[language=Python]
function Simple-Problem-Solving-Agent(percept) returns action
  static: seq, an action sequence, initially empty
          state, some description of the current world state
          goal, a goal, initially null
          problem, a problem formulation

  state <- Update-State(state, percept)

  if seq is empty then
    goal <- Formulate-Goal(state)
    problem <- Formulate-Problem(state, goal)
    seq <- Search( problem)

  action <- First(seq)
  seq <- Rest(seq)
  return action
  \end{lstlisting}
\end{example}
\begin{example}
  Consideriamo il problema "Vacanze in Romania". Bisogna formulare un viaggio da Arad a
  Bucarest sapendo che l'aereo parte domani.
  \begin{itemize}
    \item \textbf{Goal}: Arrivare a Bucarest
    \item \textbf{Formulazione del problema}:
      \begin{itemize}
        \item Stati: città della Romania
        \item Azioni: volare tra le città
      \end{itemize}
    \item \textbf{Soluzione}: Sequenza di città
  \end{itemize}
  \noindent
  Si potrebbe usare una mappa per trovare il percorso più breve (visione completa del mondo)
  e trovare una soluzione ottimale.
  Questo problema è definito da 4 componenti:
  \begin{itemize}
    \item \textbf{Stato iniziale}: ad esempio "ad Arad"
    \item \textbf{Funzione di transizione}: insieme di coppie (stato, azione) che mappano
      uno stato in un altro, ad esempio:
      \[
        S(A) = \left\{ \left< \text{Arad} \to \text{Zerind}, \text{Zerind} \right>, \ldots \right\}
      \] 
    \item \textbf{Test dell'obiettivo}: una funzione che verifica se lo stato corrente
      soddisfa l'obiettivo, ad esempio:
      \[
        Goal\text{-}Test(s) = \begin{cases}
          \text{true} & \text{se } s = \text{Bucarest} \\
          \text{false} & \text{altrimenti}
        \end{cases}
      \]
    \item \textbf{Path cost}: è una funzione che assegna un costo (additivo) a ogni azione,
      ad esempio la somma di distanze o il numero di azioni:
      \[
        c(x, a, y) \ge 0
      \] 
    \item \textbf{Soluzione}: Una sequenza di azioni che portano dallo stato iniziale allo
      stato obiettivo.
  \end{itemize}
\end{example}

\subsection{Algoritmo tree search}
Un algoritmo di ricerca ad albero esplora lo spazio degli stati partendo dallo stato iniziale
e generando nuovi stati (successori) applicando le azioni disponibili, cioè 
\textbf{espandendo} gli stati:
\begin{lstlisting}[language=Python]
function Tree-Search(problem, strategy) runction Tree-Search( problem, strategy) returns a solution, or failure
initialize the search tree using the initial state of problem
loop do
if no candidates for expansion then return failure
choose a leaf node for expansion according to strategy
if node contains a goal state then return the solution
else add successor nodes to the search tree (expansion)
endeturns a solution, or failure
  initialize the search tree using the initial state of problem
  loop do
    if no candidates for expansion then return failure
      choose a leaf node for expansion according to strategy
    if node contains a goal state then return the solution
      else add successor nodes to the search tree (expansion)
end
\end{lstlisting}

\subsubsection{Stato e nodo}
Stato e nodo non sono la stessa cosa, infatti:
\begin{itemize}
  \item \textbf{Stato}: rappresenta una configurazione dell'ambiente
  \item \textbf{Nodo}: è una struttura dati che costituisce una parte dell'albero di ricerca
    e include informazioni aggiuntive come il genitore, l'azione che ha portato a quello stato,
    il costo del percorso o la profondità nell'albero, ecc...
\end{itemize}

\subsubsection{Tree search generale}
Espandere un nodo significa generare i suoi figli, cioè i nodi successori e tutti i nodi
non esplorati sono chiamati \textbf{frontiera}.
\begin{lstlisting}[language=Python]
function Tree-Search( problem, frontier) returns a solution, or failure
  frontier <- Insert(Make-Node(problem.Initial-State))
  while not IsEmty(frontier) do
    node <- Pop(frontier)
    if problem.Goal-Test(node.State) then return node
      frontier <- InsertAll(Expand(node, problem))
  end loop
  return failure
\end{lstlisting}
La strategia è quella di scegliere l'ordine in cui i nodi vengono espansi, cioè
come viene gestita la frontiera. Le strategie sono valutate in base a:
\begin{itemize}
  \item \textbf{Completezza}: se garantisce di trovare una soluzione quando esiste
  \item \textbf{Complessità di tempo}: numero di nodi generati o espansi
  \item \textbf{Complessità di spazio}: numero massimo di nodi memorizzati in memoria
  \item \textbf{Ottimalità}: se garantisce di trovare la soluzione migliore
\end{itemize}

\end{document}
