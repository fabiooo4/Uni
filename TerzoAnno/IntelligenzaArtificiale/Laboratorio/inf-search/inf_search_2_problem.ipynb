{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning-Lab Lesson 2: Informed Search Strategies\n",
    "\n",
    "In the second session we will work on informed search\n",
    "\n",
    "### Maze Environments\n",
    "The environments used is **SmallMaze** (visible in the figure).\n",
    "\n",
    "<img src=\"images/maze.png\" width=\"300\">\n",
    "\n",
    "The agent starts in cell $(0, 2)$ and has to reach the treasure in $(4, 3)$.\n",
    "\n",
    "### Priority Queue\n",
    "\n",
    "You will need a queue ordered by priority as a queue or **PriorityQueue**. The difference between the other versions of the queue is that in **PriorityQueue**, nodes are removed from the data structure based on the current lowest value. In particular, **Node** has two useful parameters (other than those used in the previous session):\n",
    "\n",
    "- pathcost - the path cost from the root node to the current one (defaults to 0)\n",
    "- value - the value of a node. Used by PriorityQueue to order its content (defaults to 0)\n",
    "\n",
    "### Here is an example of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 1\n",
      "Added: 2\n",
      "Added: 3\n",
      "Removed state : 1, path cost: 0, value: 0\n",
      "Removed state : 3, path cost: 100, value: 5\n",
      "Removed state : 2, path cost: 1, value: 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../tools'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.ai_lab_functions import *\n",
    "\n",
    "# Create 3 nodes for state ids 1 2 3\n",
    "node_1 = Node(1) # No parent, pathcost=0, value=0\n",
    "node_2 = Node(2, node_1, node_1.pathcost + 1, 10) # Child of node_1, pathcost=1, value=10\n",
    "node_3 = Node(3, node_1, 100, 5)  # Child of node_1, pathcost=100, value=5\n",
    "\n",
    "p_queue = PriorityQueue()\n",
    "for n in (node_1, node_2, node_3):\n",
    "    p_queue.add(n)\n",
    "    print(\"Added: {}\".format(n.state))\n",
    "\n",
    "while not p_queue.is_empty():\n",
    "    node = p_queue.remove()\n",
    "    print(\"Removed state : {}, path cost: {}, value: {}\".format(node.state,node.pathcost,node.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order in which nodes are removed from the queue.\n",
    "\n",
    "## Uniform-Cost Search (UCS)\n",
    "Informed strategy can be considered as a specific implementation of Uniform-Cost Search (UCS). The following code implements a UCS, *graph search* version. The cost of performing an action is supposed to be always 1 (also in the assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_with_higher_cost(queue, node):\n",
    "    if node.state in queue:\n",
    "        if queue[node.state].pathcost > node.pathcost: \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import envs\n",
    "\n",
    "def ucs(environment):\n",
    "    \"\"\"\n",
    "    Uniform-cost search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        path: solution as a path\n",
    "    \"\"\"\n",
    "    \n",
    "    queue = PriorityQueue()\n",
    "    queue.add(Node(environment.startstate))\n",
    "    \n",
    "    explored = set()\n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    \n",
    "    while True:\n",
    "        if queue.is_empty(): \n",
    "            return None, time_cost, space_cost \n",
    "        \n",
    "        # Retrieve node from the queue\n",
    "        node = queue.remove()  \n",
    "        if node.state == environment.goalstate: \n",
    "            return build_path(node), time_cost, space_cost\n",
    "        \n",
    "        explored.add(node.state)\n",
    "        \n",
    "        # Look around\n",
    "        for action in range(environment.action_space.n):\n",
    "            \n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = Node(environment.sample(node.state, action), node, node.pathcost + 1, node.pathcost + 1)  \n",
    "            time_cost += 1\n",
    "            \n",
    "            if child.state not in queue and child.state not in explored:\n",
    "                queue.add(child)\n",
    "                \n",
    "            elif present_with_higher_cost(queue, child):\n",
    "                queue.replace(child)\n",
    "                \n",
    "        space_cost = max(space_cost, len(queue) + len(explored))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\u001b[96m##########################################\u001b[0m\n",
      "\u001b[96m#####  UNIFORM GRAPH SEARCH PROBLEM  #####\u001b[0m\n",
      "\u001b[96m##########################################\u001b[0m\n",
      "Solution: [(0, 1), (0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 61\n",
      "Max n° of nodes in memory: 16\n"
     ]
    }
   ],
   "source": [
    "# Create and render the environment\n",
    "env = gym.make(\"SmallMaze-v0\")\n",
    "env.render()\n",
    "solution, time, memory = ucs(env)\n",
    "\n",
    "CheckResult_UCS(solution, time, memory, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Heuristics\n",
    "\n",
    "Informed search requires a distance heuristic to estimate the distance between a state and the goal. You already have at your disposal these functions:\n",
    "\n",
    "- *l1_norm(p1, p2)* - Computes the L1 norm (also known as the manhattan distance) between two points specified as tuples of coordinates.\n",
    "- *l2_norm(p1, p2)* - Computes the L2 norm between two points specified as tuples of coordinates.\n",
    "- *chebyshev(p1, p2)* - Computes the Chebyshev distance between two points specified as tuples of coordinates. Similar to the L1 norm but diagonal moves are also considered.\n",
    "\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm heuristic value: 6\n",
      "L2 norm heuristic value: 4.47213595499958\n",
      "Chebyshev heuristic value: 4\n"
     ]
    }
   ],
   "source": [
    "p1 = (0, 2)\n",
    "p2 = (4, 0)\n",
    "print(\"L1 norm heuristic value: {}\".format(Heu.l1_norm(p1, p2)))\n",
    "print(\"L2 norm heuristic value: {}\".format(Heu.l2_norm(p1, p2)))\n",
    "print(\"Chebyshev heuristic value: {}\".format(Heu.chebyshev(p1, p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Greedy Best-First Search\n",
    "\n",
    "The first assignment is to implement the Greedy-best-first search algorithm on **SmallMaze**. In particular, you have to implement both *greedy_tree_search* and *greedy_graph_search* versions that will be called by the generic *greedy*. Use the L1 norm as a heuristic function first, then try the others to see the differences.\n",
    "\n",
    "The results returned by greedy must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - a tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to implement:\n",
    "- *greedy_tree_search(environment)*\n",
    "- *greedy_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function is a revised version of the present_with_higher_cost function that now checks for the value of the node, not the path cost. This is the version you should use in the graph search implementation of greedy and A***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_with_higher_value(queue, node):\n",
    "    if node.state in queue:\n",
    "        if queue[node.state].value > node.value: \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tree_search(environment, timeout=10000):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Tree search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    queue = PriorityQueue()\n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #\n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #\n",
    "    while True:\n",
    "        if time_cost >= timeout: return (\"time-out\", time_cost, space_cost) # timeout check\n",
    "        #\n",
    "        # YOUR CODE HERE ...\n",
    "        #\n",
    "        return None, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_graph_search(environment):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Graph search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #\n",
    "    explored = set()\n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #\n",
    "    return None, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function calls your implementations of greedy_tree_search and greedy_graph_search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(environment, search_type):\n",
    "    \"\"\"\n",
    "    Greedy-best-first search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        search_type: type of search - greedy_tree_search or greedy_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    path, time_cost, space_cost = search_type(environment)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code calls your *tree search* and *graph search* version of Greedy-best-first search and checks the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which heuristic did you use? (l1_norm, l2_norm, chebyshev)\n",
      "l1_norm\n",
      "\u001b[96m########################################################\u001b[0m\n",
      "\u001b[96m#######  GREEDY BEST FIRST TREE SEARCH PROBLEM  ########\u001b[0m\n",
      "\u001b[96m########################################################\u001b[0m\n",
      "Your solution: None\n",
      "N° of nodes explored: 1\n",
      "Max n° of nodes in memory: 1\n",
      "\n",
      "\u001b[91m> Your solution is not correct!\n",
      "\u001b[0m\n",
      "\u001b[96m########################################################\u001b[0m\n",
      "\u001b[96m#######  GREEDY BEST FIRST GRAPH SEARCH PROBLEM  #######\u001b[0m\n",
      "\u001b[96m########################################################\u001b[0m\n",
      "Your solution: None\n",
      "N° of nodes explored: 1\n",
      "Max n° of nodes in memory: 1\n",
      "\n",
      "\u001b[91m> Your solution is not correct, should be: [(0, 3), (1, 3), (2, 3), (2, 2), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "\n",
    "solution_ts, time_ts, memory_ts = greedy(environment, greedy_tree_search)\n",
    "solution_gs, time_gs, memory_gs = greedy(environment, greedy_graph_search)\n",
    "heuristic = str(input('Which heuristic did you use? (l1_norm, l2_norm, chebyshev)\\n'))\n",
    "\n",
    "results = CheckResult_L2A1([solution_ts, time_ts, memory_ts], [solution_gs, time_gs, memory_gs], heuristic, env)\n",
    "results.check_sol_ts()\n",
    "results.check_sol_gs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: A* Search\n",
    "The second assignment is to implement the A* search algorithm on SmallMaze. In particular, you have to implement both astar_tree_search and astar_graph_search versions that the generic astar will call. Use the L1 norm as a heuristic function first, then try the others to see the differences.\n",
    "\n",
    "The results returned by astar must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - a tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory simultaneously.\n",
    "\n",
    "Functions to implement:\n",
    "- *astar_tree_search(environment)*\n",
    "- *astar_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_tree_search(environment):\n",
    "    \"\"\"\n",
    "    A* Tree search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    queue = PriorityQueue()\n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #    \n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #\n",
    "    return None, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_graph_search(environment):\n",
    "    \"\"\"\n",
    "    A* Graph Search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #\n",
    "    explored = set()\n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    #\n",
    "    # YOUR CODE HERE ...\n",
    "    #\n",
    "    return None, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function calls your implementations of astar_tree_search and astar_graph_search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(environment, search_type):\n",
    "    \"\"\"\n",
    "    A* search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - astar_tree_search or astar_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    path, time_cost, space_cost = search_type(environment)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code calls your *tree search* and *graph search* version of A* search and checks the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which heuristic did you use? (l1_norm, l2_norm, chebyshev)\n",
      "l1_norm\n",
      "\u001b[96m#########################################\u001b[0m\n",
      "\u001b[96m#######  A* TREE SEARCH PROBLEM  ########\u001b[0m\n",
      "\u001b[96m#########################################\u001b[0m\n",
      "Your solution: None\n",
      "N° of nodes explored: 1\n",
      "Max n° of nodes in memory: 1\n",
      "\n",
      "\u001b[91m> Your solution is not correct, should be: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "\u001b[0m\n",
      "\u001b[96m##########################################\u001b[0m\n",
      "\u001b[96m#######  A* GRAPH SEARCH PROBLEM  ########\u001b[0m\n",
      "\u001b[96m##########################################\u001b[0m\n",
      "Your solution: None\n",
      "N° of nodes explored: 1\n",
      "Max n° of nodes in memory: 1\n",
      "\n",
      "\u001b[91m> Your solution is not correct, should be: [(0, 1), (1, 1), (2, 1), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "\n",
    "solution_ts, time_ts, memory_ts = astar(environment, astar_tree_search)\n",
    "solution_gs, time_gs, memory_gs = astar(environment, astar_graph_search)\n",
    "heuristic = str(input('Which heuristic did you use? (l1_norm, l2_norm, chebyshev)\\n'))\n",
    "\n",
    "results = CheckResult_L2A2([solution_ts, time_ts, memory_ts], [solution_gs, time_gs, memory_gs], heuristic, env)\n",
    "results.check_sol_ts()\n",
    "results.check_sol_gs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Now that you have correctly implemented both Greedy-best-first and A* what can you say about the solutions they compute? Are there significant differences in the stats? Try to play with other heuristics as well and see if your results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
