{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning-Lab Lesson 2: Informed Search Strategies\n",
    "\n",
    "In the second session we will work on informed search\n",
    "\n",
    "### Maze Environments\n",
    "The environments used is **SmallMaze** (visible in the figure).\n",
    "\n",
    "<img src=\"images/maze.png\" width=\"300\">\n",
    "\n",
    "The agent starts in cell $(0, 2)$ and has to reach the treasure in $(4, 3)$.\n",
    "\n",
    "### Priority Queue\n",
    "\n",
    "You will need a queue ordered by priority as a queue or **PriorityQueue**. The difference between the other versions of the queue is that in **PriorityQueue**, nodes are removed from the data structure based on the current lowest value. In particular, **Node** has two useful parameters (other than those used in the previous session):\n",
    "\n",
    "- pathcost - the path cost from the root node to the current one (defaults to 0)\n",
    "- value - the value of a node. Used by PriorityQueue to order its content (defaults to 0)\n",
    "\n",
    "### Here is an example of usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added: 1\n",
      "Added: 2\n",
      "Added: 3\n",
      "Removed state : 1, path cost: 0, value: 0\n",
      "Removed state : 3, path cost: 100, value: 5\n",
      "Removed state : 2, path cost: 1, value: 10\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../tools'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utils.ai_lab_functions import *\n",
    "\n",
    "# Create 3 nodes for state ids 1 2 3\n",
    "node_1 = Node(1) # No parent, pathcost=0, value=0\n",
    "node_2 = Node(2, node_1, node_1.pathcost + 1, 10) # Child of node_1, pathcost=1, value=10\n",
    "node_3 = Node(3, node_1, 100, 5)  # Child of node_1, pathcost=100, value=5\n",
    "\n",
    "p_queue = PriorityQueue()\n",
    "for n in (node_1, node_2, node_3):\n",
    "    p_queue.add(n)\n",
    "    print(\"Added: {}\".format(n.state))\n",
    "\n",
    "while not p_queue.is_empty():\n",
    "    node = p_queue.remove()\n",
    "    print(\"Removed state : {}, path cost: {}, value: {}\".format(node.state,node.pathcost,node.value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order in which nodes are removed from the queue.\n",
    "\n",
    "## Uniform-Cost Search (UCS)\n",
    "Informed strategy can be considered as a specific implementation of Uniform-Cost Search (UCS). The following code implements a UCS, *graph search* version. The cost of performing an action is supposed to be always 1 (also in the assignments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_with_higher_cost(queue, node):\n",
    "    if node.state in queue:\n",
    "        if queue[node.state].pathcost > node.pathcost: \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import envs\n",
    "\n",
    "def ucs(environment):\n",
    "    \"\"\"\n",
    "    Uniform-cost search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        path: solution as a path\n",
    "    \"\"\"\n",
    "    \n",
    "    queue = PriorityQueue()\n",
    "    queue.add(Node(environment.startstate))\n",
    "    \n",
    "    explored = set()\n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    \n",
    "    while True:\n",
    "        if queue.is_empty(): \n",
    "            return None, time_cost, space_cost \n",
    "        \n",
    "        # Retrieve node from the queue\n",
    "        node = queue.remove()  \n",
    "        if node.state == environment.goalstate: \n",
    "            return build_path(node), time_cost, space_cost\n",
    "        \n",
    "        explored.add(node.state)\n",
    "        \n",
    "        # Look around\n",
    "        for action in range(environment.action_space.n):\n",
    "            \n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = Node(environment.sample(node.state, action), node, node.pathcost + 1, node.pathcost + 1)  \n",
    "            time_cost += 1\n",
    "            \n",
    "            if child.state not in queue and child.state not in explored:\n",
    "                queue.add(child)\n",
    "                \n",
    "            elif present_with_higher_cost(queue, child):\n",
    "                queue.replace(child)\n",
    "                \n",
    "        space_cost = max(space_cost, len(queue) + len(explored))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's see the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['C' 'C' 'S' 'C']\n",
      " ['C' 'C' 'W' 'C']\n",
      " ['C' 'C' 'C' 'C']\n",
      " ['C' 'W' 'W' 'W']\n",
      " ['C' 'C' 'C' 'G']]\n",
      "\n",
      "\u001b[96m##########################################\u001b[0m\n",
      "\u001b[96m#####  UNIFORM GRAPH SEARCH PROBLEM  #####\u001b[0m\n",
      "\u001b[96m##########################################\u001b[0m\n",
      "Solution: [(0, 1), (0, 0), (1, 0), (2, 0), (3, 0), (4, 0), (4, 1), (4, 2), (4, 3)]\n",
      "N° of nodes explored: 61\n",
      "Max n° of nodes in memory: 16\n"
     ]
    }
   ],
   "source": [
    "# Create and render the environment\n",
    "env = gym.make(\"SmallMaze-v0\")\n",
    "env.render()\n",
    "solution, time, memory = ucs(env)\n",
    "\n",
    "CheckResult_UCS(solution, time, memory, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Heuristics\n",
    "\n",
    "Informed search requires a distance heuristic to estimate the distance between a state and the goal. You already have at your disposal these functions:\n",
    "\n",
    "- *l1_norm(p1, p2)* - Computes the L1 norm (also known as the manhattan distance) between two points specified as tuples of coordinates.\n",
    "- *l2_norm(p1, p2)* - Computes the L2 norm between two points specified as tuples of coordinates.\n",
    "- *chebyshev(p1, p2)* - Computes the Chebyshev distance between two points specified as tuples of coordinates. Similar to the L1 norm but diagonal moves are also considered.\n",
    "\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm heuristic value: 6\n",
      "L2 norm heuristic value: 4.47213595499958\n",
      "Chebyshev heuristic value: 4\n"
     ]
    }
   ],
   "source": [
    "p1 = (0, 2)\n",
    "p2 = (4, 0)\n",
    "print(\"L1 norm heuristic value: {}\".format(Heu.l1_norm(p1, p2)))\n",
    "print(\"L2 norm heuristic value: {}\".format(Heu.l2_norm(p1, p2)))\n",
    "print(\"Chebyshev heuristic value: {}\".format(Heu.chebyshev(p1, p2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1: Greedy Best-First Search\n",
    "\n",
    "The first assignment is to implement the Greedy-best-first search algorithm on **SmallMaze**. In particular, you have to implement both *greedy_tree_search* and *greedy_graph_search* versions that will be called by the generic *greedy*. Use the L1 norm as a heuristic function first, then try the others to see the differences.\n",
    "\n",
    "The results returned by greedy must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - a tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory simultaneously.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to implement:\n",
    "- *greedy_tree_search(environment)*\n",
    "- *greedy_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function is a revised version of the present_with_higher_cost function that now checks for the value of the node, not the path cost. This is the version you should use in the graph search implementation of greedy and A***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def present_with_higher_value(queue, node):\n",
    "    if node.state in queue:\n",
    "        if queue[node.state].value > node.value: \n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_tree_search(environment, heuristic_function, timeout=10000):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Tree search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    queue = PriorityQueue()\n",
    "    queue.add(Node(environment.startstate))\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "\n",
    "    while True:\n",
    "        if time_cost >= timeout: return (\"time-out\", time_cost, space_cost) # timeout check\n",
    "        if queue.is_empty(): \n",
    "            return None, time_cost, space_cost \n",
    "        \n",
    "        # Retrieve node from the queue\n",
    "        node = queue.remove()  \n",
    "        if node.state == environment.goalstate: \n",
    "            return build_path(node), time_cost, space_cost\n",
    "                \n",
    "        # Look around\n",
    "        for action in range(environment.action_space.n):\n",
    "            \n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = Node(\n",
    "                environment.sample(node.state, action),\n",
    "                node, node.pathcost + 1,\n",
    "                heuristic_function(\n",
    "                    environment.state_to_pos(environment.sample(node.state, action)),\n",
    "                    goalpos\n",
    "                )\n",
    "            )  \n",
    "            time_cost += 1\n",
    "            \n",
    "            queue.add(child)\n",
    "                \n",
    "        space_cost = max(space_cost, len(queue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_graph_search(environment, heuristic_function):\n",
    "    \"\"\"\n",
    "    Greedy-best-first Graph search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    queue = PriorityQueue()\n",
    "    queue.add(Node(environment.startstate))\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    explored = set()\n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    while True:\n",
    "        if queue.is_empty(): \n",
    "            return None, time_cost, space_cost \n",
    "        \n",
    "        # Retrieve node from the queue\n",
    "        node = queue.remove()  \n",
    "        if node.state == environment.goalstate: \n",
    "            return build_path(node), time_cost, space_cost\n",
    "        \n",
    "        explored.add(node.state)\n",
    "        \n",
    "        # Look around\n",
    "        for action in range(environment.action_space.n):\n",
    "            \n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = Node(\n",
    "                environment.sample(node.state, action),\n",
    "                node, node.pathcost + 1,\n",
    "                heuristic_function(\n",
    "                    environment.state_to_pos(environment.sample(node.state, action)),\n",
    "                    goalpos\n",
    "                )\n",
    "            )  \n",
    "            time_cost += 1\n",
    "            \n",
    "            if child.state not in queue and child.state not in explored:\n",
    "                queue.add(child)\n",
    "                \n",
    "            elif present_with_higher_value(queue, child):\n",
    "                queue.replace(child)\n",
    "                \n",
    "        space_cost = max(space_cost, len(queue) + len(explored))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function calls your implementations of greedy_tree_search and greedy_graph_search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(environment, search_type, heuristic_function):\n",
    "    \"\"\"\n",
    "    Greedy-best-first search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        search_type: type of search - greedy_tree_search or greedy_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    path, time_cost, space_cost = search_type(environment, heuristic_function)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code calls your *tree search* and *graph search* version of Greedy-best-first search and checks the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "\n",
    "heuristic_function = Heu.l1_norm\n",
    " \n",
    "solution_ts, time_ts, memory_ts = greedy(environment, greedy_tree_search, heuristic_function)\n",
    "solution_gs, time_gs, memory_gs = greedy(environment, greedy_graph_search, heuristic_function)\n",
    "\n",
    "heuristic = \"\"\n",
    "if heuristic_function == Heu.l1_norm:\n",
    "    heuristic = \"l1_norm\"\n",
    "elif heuristic_function == Heu.l2_norm:\n",
    "    heuristic = \"l2_norm\"\n",
    "elif heuristic_function == Heu.chebyshev:\n",
    "    heuristic = \"chebyshev\"\n",
    "    \n",
    "results = CheckResult_L2A1([solution_ts, time_ts, memory_ts], [solution_gs, time_gs, memory_gs], heuristic, env)\n",
    "results.check_sol_ts()\n",
    "results.check_sol_gs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: A* Search\n",
    "The second assignment is to implement the A* search algorithm on SmallMaze. In particular, you have to implement both astar_tree_search and astar_graph_search versions that the generic astar will call. Use the L1 norm as a heuristic function first, then try the others to see the differences.\n",
    "\n",
    "The results returned by astar must be in the following form (path, time_cost, space_cost), more in detail:\n",
    "\n",
    "- **path** - a tuple of state identifiers forming a path from the start state to the goal state. None if no solution is found.\n",
    "- **time_cost** - the number of nodes checked during the exploration.\n",
    "- **space_cost** - the maximum number of nodes in memory simultaneously.\n",
    "\n",
    "Functions to implement:\n",
    "- *astar_tree_search(environment)*\n",
    "- *astar_graph_search(environment)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_tree_search(environment, heuristic_function):\n",
    "    \"\"\"\n",
    "    A* Tree search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "\n",
    "    queue = PriorityQueue()\n",
    "    queue.add(Node(environment.startstate))\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "\n",
    "    while True:\n",
    "        if queue.is_empty(): \n",
    "            return None, time_cost, space_cost \n",
    "        \n",
    "        # Retrieve node from the queue\n",
    "        node = queue.remove()  \n",
    "        if node.state == environment.goalstate: \n",
    "            return build_path(node), time_cost, space_cost\n",
    "                \n",
    "        # Look around\n",
    "        for action in range(environment.action_space.n):\n",
    "            \n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = Node(\n",
    "                environment.sample(node.state, action),\n",
    "                node, node.pathcost + 1,\n",
    "                (node.pathcost + 1) + heuristic_function(\n",
    "                    environment.state_to_pos(environment.sample(node.state, action)),\n",
    "                    goalpos\n",
    "                )\n",
    "            )  \n",
    "            time_cost += 1\n",
    "            \n",
    "            queue.add(child)\n",
    "                \n",
    "        space_cost = max(space_cost, len(queue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar_graph_search(environment, heuristic_function):\n",
    "    \"\"\"\n",
    "    A* Graph Search\n",
    "    \n",
    "    Args:\n",
    "        problem: OpenAI Gym environment\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    queue = PriorityQueue()\n",
    "    queue.add(Node(environment.startstate))\n",
    "    goalpos = environment.state_to_pos(environment.goalstate)\n",
    "    \n",
    "    explored = set()\n",
    "    time_cost = 1\n",
    "    space_cost = 1\n",
    "    while True:\n",
    "        if queue.is_empty(): \n",
    "            return None, time_cost, space_cost \n",
    "        \n",
    "        # Retrieve node from the queue\n",
    "        node = queue.remove()  \n",
    "        if node.state == environment.goalstate: \n",
    "            return build_path(node), time_cost, space_cost\n",
    "        \n",
    "        explored.add(node.state)\n",
    "        \n",
    "        # Look around\n",
    "        for action in range(environment.action_space.n):\n",
    "            \n",
    "            # Child node where value and pathcost are both the pathcost of parent + 1\n",
    "            child = Node(\n",
    "                environment.sample(node.state, action),\n",
    "                node, node.pathcost + 1,\n",
    "                (node.pathcost + 1) + heuristic_function(\n",
    "                    environment.state_to_pos(environment.sample(node.state, action)),\n",
    "                    goalpos\n",
    "                )\n",
    "            )  \n",
    "            time_cost += 1\n",
    "            \n",
    "            if child.state not in queue and child.state not in explored:\n",
    "                queue.add(child)\n",
    "                \n",
    "            elif present_with_higher_value(queue, child):\n",
    "                queue.replace(child)\n",
    "                \n",
    "        space_cost = max(space_cost, len(queue) + len(explored))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function calls your implementations of astar_tree_search and astar_graph_search:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astar(environment, search_type, heuristic_function):\n",
    "    \"\"\"\n",
    "    A* search\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        search_type: type of search - astar_tree_search or astar_graph_search (function pointer)\n",
    "        \n",
    "    Returns:\n",
    "        (path, time_cost, space_cost): solution as a path and stats.\n",
    "    \"\"\"\n",
    "    \n",
    "    path, time_cost, space_cost = search_type(environment, heuristic_function)\n",
    "    return path, time_cost, space_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following code calls your *tree search* and *graph search* version of A* search and checks the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'heuristic_fuction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15148/3200474584.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mheuristic_function\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mheuristic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"l1_norm\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32melif\u001b[0m \u001b[0mheuristic_fuction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mheuristic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"l2_norm\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mheuristic_function\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mHeu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchebyshev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'heuristic_fuction' is not defined"
     ]
    }
   ],
   "source": [
    "envname = \"SmallMaze-v0\"\n",
    "environment = gym.make(envname)\n",
    "\n",
    "heuristic_function = Heu.l2_norm\n",
    "\n",
    "solution_ts, time_ts, memory_ts = astar(environment, astar_tree_search, heuristic_function)\n",
    "solution_gs, time_gs, memory_gs = astar(environment, astar_graph_search, heuristic_function)\n",
    "\n",
    "heuristic = \"\"\n",
    "if heuristic_function == Heu.l1_norm:\n",
    "    heuristic = \"l1_norm\"\n",
    "elif heuristic_function == Heu.l2_norm:\n",
    "    heuristic = \"l2_norm\"\n",
    "elif heuristic_function == Heu.chebyshev:\n",
    "    heuristic = \"chebyshev\"\n",
    "\n",
    "results = CheckResult_L2A2([solution_ts, time_ts, memory_ts], [solution_gs, time_gs, memory_gs], heuristic, env)\n",
    "results.check_sol_ts()\n",
    "results.check_sol_gs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "Now that you have correctly implemented both Greedy-best-first and A* what can you say about the solutions they compute? Are there significant differences in the stats? Try to play with other heuristics as well and see if your results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
