{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning-Lab lesson 4: Reinforcement Learning\n",
    "\n",
    "In this tutorial we will implement two model free RL algorithms: Q-Learning and SARSA.\n",
    "\n",
    "## Cliff Environment\n",
    "The environment used is **Cliff** (taken from the book of Sutton and Barto as visible in the figure)\n",
    "\n",
    "![Cliff](images/cliff.png)\n",
    "\n",
    "The agent starts in cell $(3, 0)$ and has to reach the goal in $(3, 11)$. Falling from the cliff resets the position to the start state (the episode ends only when the goal state is reached). All other cells are safe. **Action dinamycs is deterministic**, meaning that the agent always reaches the desired next state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../tools'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import gym, envs\n",
    "from utils.ai_lab_functions import *\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "env = gym.make(\"Cliff-v0\")\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell types are the following:\n",
    "\n",
    "- x - Start position\n",
    "- o - Safe\n",
    "- C - Cliff\n",
    "- T - Goal\n",
    "\n",
    "Rewards:\n",
    "\n",
    "- -1 for each \"safe\" cell (o)\n",
    "- -100 for falling from the cliff (C)\n",
    "\n",
    "In addition to the functionalities of the environments you have been using in the previous sessions, there are also a few more:\n",
    "\n",
    "- step(action): the agent **execute action in the environment** from the current state. Returns a tuple (new_state, reward, done, info) where:\n",
    "    - new_state: is the new state reached as a consequence of the agent's last action\n",
    "    - reward: the reward obtained by the agent\n",
    "    - done: True if the episode has ended, False otherwise\n",
    "    - info: not used, you can safely discard it\n",
    "\n",
    "- reset(): the environment is reset and the agent goes back to the starting position. Returns the initial state id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: (3, 0) \n",
      "Action: 0 \n",
      "New State: (2, 0) \n",
      "Reward: -1 \n",
      "Done: False\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "action = 0 # Go UP\n",
    "new_state, reward, done, _ = env.step(0)\n",
    "\n",
    "print(\"State: {} \\nAction: {} \\nNew State: {} \\nReward: {} \\nDone: {}\".format(env.state_to_pos(state), action, env.state_to_pos(new_state), reward, done))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to execute a random policy in the environment: we create such policy as usual, we reset the environment to its initial state and also set a maximum number of steps for the episod. Then we execute a loop where at each iteration a step is performed by using the action prescribed by the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: \n",
      " [[0 0 0 0 3 1 1 3 0 2 2 3]\n",
      " [3 3 2 2 3 0 0 0 1 1 1 2]\n",
      " [3 3 0 0 3 0 1 0 2 0 0 1]\n",
      " [0 2 0 2 0 3 0 3 1 2 2 3]] \n",
      " Total Reward of Random Policy: : -20 \n",
      " Episode Length 20 \n"
     ]
    }
   ],
   "source": [
    "policy = np.random.choice(env.action_space.n, env.observation_space.n)\n",
    "state = env.reset()\n",
    "ep_limit = 20 #maximum number of steps the policy will execute\n",
    "\n",
    "el = 0 #initialize counter to accumulate the number of steps the policy execute (episode length)\n",
    "total_reward = 0 #initialize accumulate to sum the rewards received at each step \n",
    "\n",
    "# Episode execution loop\n",
    "for _ in range(ep_limit):\n",
    "    next_state, reward, done, _ = env.step(policy[state])  # Execute a step\n",
    "    total_reward += reward\n",
    "    el += 1\n",
    "    if done or el == ep_limit:  # If done == True, the episode has ended\n",
    "        break\n",
    "    state = next_state\n",
    "    \n",
    "print(\"Policy: \\n {} \\n Total Reward of Random Policy: : {} \\n Episode Length {} \".format(policy.reshape(4,12),total_reward,el))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1:  Q-Learning\n",
    "Your first assignment is to implement the Q-Learning algorithm on **Cliff**. You can use the implement exploration functions: $\\epsilon$-greedy and Softmax. \n",
    "\n",
    "The solution returned by your Q-Learning implementation must be a tuple (policy, rewards, lengths) where:\n",
    "\n",
    "- *policy*: array of action identifiers where the $i$-th action refers to the $i$-th state\n",
    "- *rewards*: array of rewards where the $i$-th reward refers to the $i$-th episode of the training performed\n",
    "- *lengths*: array of lengths where the $i$-th length refers to the $i$-th episode of the training performed (length in number of steps)\n",
    "\n",
    "Implemented exploration functions:\n",
    "- *epsilon_greedy(q, state, epsilon)*\n",
    "- *softmax(softmax(q, state, temp)*\n",
    "\n",
    "**Functions to implement:**\n",
    "- *q_learning(environment, episodes, alpha, gamma, expl_func, expl_param)*\n",
    "\n",
    "#### Note on softmax #### \n",
    "The implementation of softmax requires to **draw a number given a specific probability distribution**. We can use the random.choice(a,p) function of the NumPy library to do this. \n",
    "\n",
    "Where: \n",
    "- *a: an array or an int, If an array, a random sample is generated from its elements. If an int, the random sample is generated as if it were np.arange(a)*\n",
    "- *p: the probabilities associated with each entry in a. If not given, the sample assumes a uniform distribution over all entries in a.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing among: [0 1 2 3 4] with probability [0.1, 0.2, 0.5, 0.1, 0.1]: 2\n",
      "Choosing among: [0 1 2 2 0] with probability [0.1, 0.2, 0.5, 0.1, 0.1]: 1\n",
      "Values of all actions, max and argmax for the first 5 states\n",
      "q[0]: [0.145 0.727 0.367 0.038], max : 0.727, argmax 1\n",
      "q[1]: [0.891 0.903 0.734 0.798], max : 0.903, argmax 1\n",
      "q[2]: [0.364 0.034 0.4   0.251], max : 0.400, argmax 2\n",
      "q[3]: [0.524 0.03  0.641 0.729], max : 0.729, argmax 3\n",
      "q[4]: [0.25  0.269 0.166 0.346], max : 0.346, argmax 3\n",
      "array of first 5 states with max value across actions: \n",
      " [0.727 0.903 0.4   0.729 0.346] \n",
      "array of first 5 states with maximum action \n",
      " [1 1 2 3 3]\n"
     ]
    }
   ],
   "source": [
    "#Example with a as int, choice is made on among the 5 choices in the vector [0,1,2,3,4], \n",
    "#the 3rd is the one that is most likely to be chosen (highest probability value).\n",
    "\n",
    "q = [0.1, 0.2, 0.5, 0.1, 0.1]\n",
    "c1 = np.random.choice(5, p = q)\n",
    "print(\"Choosing among: {} with probability {}: {}\".format(np.arange(5),q,c1))\n",
    "\n",
    "a = np.random.choice(3, 5)\n",
    "c2 = np.random.choice(a, p = q)\n",
    "print(\"Choosing among: {} with probability {}: {}\".format(a,q,c2))\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=3) #set decimal numer to 3 in array\n",
    "#Example to extract the maximum value and the index with maximum value from an array \n",
    "q = np.random.rand(env.observation_space.n, env.action_space.n) # Randomly intialization of Q(s, a)\n",
    "print(\"Values of all actions, max and argmax for the first 5 states\")\n",
    "for i in range(5): \n",
    "    print(\"q[{}]: {}, max : {:.3f}, argmax {}\".format(i,q[i],q[i].max(),q[i].argmax()))\n",
    "\n",
    "print(\"array of first 5 states with max value across actions: \\n {} \\narray of first 5 states with maximum action \\n {}\".format(q.max(axis=1)[:5],q.argmax(axis=1)[:5]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploration functions to be used in the algorithm:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy(q, state, epsilon):\n",
    "    \"\"\"\n",
    "    Epsilon-greedy action selection function\n",
    "    \n",
    "    Args:\n",
    "        q: q table\n",
    "        state: agent's current state\n",
    "        epsilon: epsilon parameter\n",
    "    \n",
    "    Returns:\n",
    "        action id\n",
    "    \"\"\"\n",
    "    if np.random.random() < epsilon: #enters the if only if the random number is less than epsilon (i.e., with probability  epsilon)\n",
    "        return np.random.choice(q.shape[1]) #the size of first dimension of q is number of states, the second is number of actions \n",
    "    return q[state].argmax() #q[state] is a vector of q-values indexed by actions\n",
    "\n",
    "def softmax(q, state, temp):\n",
    "    \"\"\"\n",
    "    Softmax action selection function\n",
    "    \n",
    "    Args:\n",
    "    q: q table\n",
    "    state: agent's current state\n",
    "    temp: temperature parameter\n",
    "    \n",
    "    Returns:\n",
    "        action id\n",
    "    \"\"\"\n",
    "    e = np.exp(q[state] / temp) #a vector indexed by action where each value is e^(q(s,a)/T)\n",
    "    return np.random.choice(q.shape[1], p=e / e.sum()) # choose an action with probability e^(q(s,a)/T)/sum_{a'} e^(q(s,a')/T)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The following function has to be implemented:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_learning(environment, episodes, alpha, gamma, expl_func, expl_param):\n",
    "    \"\"\"\n",
    "    Performs the Q-Learning algorithm for a specific environment\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        episodes: number of episodes for training\n",
    "        alpha: alpha parameter\n",
    "        gamma: gamma parameter\n",
    "        expl_func: exploration function (epsilon_greedy, softmax)\n",
    "        expl_param: exploration parameter (epsilon or T)\n",
    "    \n",
    "    Returns:\n",
    "        (policy, rewards, lengths): final policy, rewards for each episode [array], length of each episode [array]\n",
    "    \"\"\"\n",
    "    \n",
    "    q = np.zeros((environment.observation_space.n, environment.action_space.n))  # Q(s, a)\n",
    "    rews = np.zeros(episodes)\n",
    "    lengths = np.zeros(episodes)\n",
    "    #\n",
    "    # Code Here!\n",
    "    #\n",
    "    policy = q.argmax(axis=1) # q.argmax(axis=1) automatically extract the policy from the q table\n",
    "    return policy, rews, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that since the executions are stochastic, the policy could differ: the important thing is that the policy obtained using Q-Learning chooses the shortest path toward the goal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "\n",
      "Execution time: 0.0018s\n",
      "\n",
      "\u001b[96m#####################################################\u001b[0m\n",
      "\u001b[96m#######  Environment: Cliff-v0 \tQ-Learning  #########\u001b[0m\n",
      "\u001b[96m#####################################################\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92m===> Your policy:\n",
      "\n",
      "[['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92m===> Our policy:\n",
      "\n",
      "[['D' 'U' 'D' 'R' 'D' 'R' 'D' 'D' 'L' 'D' 'D' 'D']\n",
      " ['D' 'U' 'R' 'R' 'R' 'U' 'D' 'R' 'D' 'R' 'R' 'D']\n",
      " ['R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'D']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env_name = \"Cliff-v0\"\n",
    "env = gym.make(env_name)\n",
    "env.render()\n",
    "print()\n",
    "\n",
    "# Learning parameters\n",
    "episodes = 500\n",
    "alpha = .3\n",
    "gamma = .9\n",
    "epsilon = .1\n",
    "\n",
    "t = timer()\n",
    "\n",
    "# Q-Learning epsilon greedy\n",
    "policy, rewards, lengths = q_learning(env, episodes, alpha, gamma, epsilon_greedy, epsilon)\n",
    "print(f\"Execution time: {round(timer() - t, 4)}s\") \n",
    "policy_render = np.vectorize(env.actions.get)(policy.reshape(env.shape))\n",
    "_ = run_episode(env, policy, 20)\n",
    "\n",
    "results = CheckResult_L5(policy_render)\n",
    "results.check_qlearning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: SARSA\n",
    "Your second assignment is to implement the SARSA algorithm on **Cliff**. In particular you need to implement both $\\epsilon$-greedy and Softmax versions for the exploration heuristic (you can reuse the same functions of Assignment 1). The solution returned must be a tuple (policy, rewards, lengths) where:\n",
    "\n",
    "- *policy*: array of action identifiers where the $i$-th action refers to the $i$-th state\n",
    "- *rewards*: array of rewards where the $i$-th reward refers to the $i$-th episode of the training performed\n",
    "- *lengths*: array of lengths where the $i$-th length refers to the $i$-th episode of the training performed (length in number of steps)\n",
    "\n",
    "**Functions to implement:**\n",
    "\n",
    "- *SARSA(environment, episodes, alpha, gamma, expl_func, expl_param)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa(environment, episodes, alpha, gamma, expl_func, expl_param):\n",
    "    \"\"\"\n",
    "    Performs the SARSA algorithm for a specific environment\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI gym environment\n",
    "        episodes: number of episodes for training\n",
    "        alpha: alpha parameter\n",
    "        gamma: gamma parameter\n",
    "        expl_func: exploration function (epsilon_greedy, softmax)\n",
    "        expl_param: exploration parameter (epsilon, T)\n",
    "    \n",
    "    Returns:\n",
    "        (policy, rewards, lengths): final policy, rewards for each episode [array], length of each episode [array]\n",
    "    \"\"\"\n",
    "\n",
    "    q = np.zeros((environment.observation_space.n, environment.action_space.n))  # Q(s, a)\n",
    "    rews = np.zeros(episodes)\n",
    "    lengths = np.zeros(episodes)\n",
    "    #\n",
    "    # Code Here!\n",
    "    #\n",
    "    policy = q.argmax(axis=1) # q.argmax(axis=1) automatically extract the policy from the q table\n",
    "    return policy, rews, lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice that since the executions are stochastic, the policy could differ: the important thing is that the policy obtained using SARSA chooses the longer but safer path toward the goal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "\n",
      "Execution time: 0.0003s\n",
      "\n",
      "\u001b[96m################################################\u001b[0m\n",
      "\u001b[96m#######  Environment: Cliff-v0 \tSARSA  #########\u001b[0m\n",
      "\u001b[96m################################################\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92m===> Your policy:\n",
      "\n",
      "[['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']]\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92m===> Our policy:\n",
      "\n",
      "[['R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'D']\n",
      " ['U' 'U' 'L' 'U' 'U' 'U' 'R' 'R' 'U' 'U' 'R' 'D']\n",
      " ['U' 'U' 'L' 'U' 'R' 'R' 'L' 'R' 'U' 'U' 'R' 'D']\n",
      " ['U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U' 'U']]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env_name = \"Cliff-v0\"\n",
    "env = gym.make(env_name)\n",
    "env.render()\n",
    "print()\n",
    "\n",
    "# Learning parameters\n",
    "episodes = 500\n",
    "alpha = .3\n",
    "gamma = .9\n",
    "epsilon = .1\n",
    "\n",
    "t = timer()\n",
    "\n",
    "# SARSA epsilon greedy\n",
    "policy, rews, lengths = sarsa(env, episodes, alpha, gamma, epsilon_greedy, epsilon)\n",
    "print(f\"Execution time: {round(timer() - t, 4)}s\") \n",
    "_ = run_episode(env, policy, 20)\n",
    "policy_render = np.vectorize(env.actions.get)(policy.reshape(env.shape))\n",
    "\n",
    "\n",
    "results = CheckResult_L5(policy_render)\n",
    "results.check_sarsa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison\n",
    "\n",
    "The following code performs a comparison between the 2 reinforcement learning algorithms: *Q-Learning* and *SARSA*. Execute the following code and analyze the charts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###########################################################\n",
      "################ Environment: Cliff-v0 ####################\n",
      "###########################################################\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "Execution time: 0.0066s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "envname = \"Cliff-v0\"\n",
    "print()\n",
    "print(\"###########################################################\")\n",
    "print(\"################ Environment: Cliff-v0 ####################\")\n",
    "print(\"###########################################################\\n\")\n",
    "\n",
    "env = gym.make(envname)\n",
    "env.render()\n",
    "\n",
    "# Learning parameters\n",
    "episodes = 600\n",
    "ep_limit = 50\n",
    "alpha = .3\n",
    "gamma = .9\n",
    "epsilon = .1\n",
    "temp = 1\n",
    "\n",
    "rewser = []\n",
    "lenser = []\n",
    "\n",
    "litres = np.arange(1, episodes + 1)  # Learning iteration values\n",
    "window = 50  # Rolling window\n",
    "\n",
    "t = timer()\n",
    "\n",
    "# Q-Learning\n",
    "_, rews, lengths = q_learning(env, episodes, alpha, gamma, epsilon_greedy, epsilon)\n",
    "#_, rews, lengths = q_learning(env, episodes, alpha, gamma, softmax, temp)\n",
    "rews = rolling(rews, window)\n",
    "rewser.append({\"x\": np.arange(1, len(rews) + 1), \"y\": rews, \"ls\": \"-\", \"label\": \"Q-Learning\"})\n",
    "lengths = rolling(lengths, window)\n",
    "lenser.append({\"x\": np.arange(1, len(lengths) + 1), \"y\": lengths, \"ls\": \"-\", \"label\": \"Q-Learning\"})\n",
    "\n",
    "# SARSA\n",
    "_, rews, lengths = sarsa(env, episodes, alpha, gamma, epsilon_greedy, epsilon)\n",
    "#_, rews, lengths = q_learning(env, episodes, alpha, gamma, softmax, temp)\n",
    "rews = rolling(rews, window)\n",
    "rewser.append({\"x\": np.arange(1, len(rews) + 1), \"y\": rews, \"label\": \"SARSA\"})\n",
    "lengths = rolling(lengths, window)\n",
    "lenser.append({\"x\": np.arange(1, len(lengths) + 1), \"y\": lengths, \"label\": \"SARSA\"})\n",
    "\n",
    "print(\"Execution time: {0}s\".format(round(timer() - t, 4)))\n",
    "\n",
    "plot(rewser, \"Rewards\", \"Episodes\", \"Rewards\")\n",
    "plot(lenser, \"Lengths\", \"Episodes\", \"Lengths\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for comparison can be found here below. Notice that since the executions are stochastic the charts could differ: the important thing is the global trend.\n",
    "\n",
    "**Algorithms Reward comparison**\n",
    "<img src=\"images/results-reward.png\" width=\"600\">\n",
    "\n",
    "**Algorithms Episode Length comparison**\n",
    "<img src=\"images/results-length.png\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
